<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; Contextualizing statistics – Patterns from Static: Philosophy and the Question Concerning Statistics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./ch1.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-99913b7803b80b0c1d2b970a25816663.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./ch2.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Contextualizing statistics</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Patterns from Static: Philosophy and the Question Concerning Statistics</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Philosophy, statistics, and the philosophy of statistics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch2.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Contextualizing statistics</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#subsubsec:types" id="toc-subsubsec:types" class="nav-link active" data-scroll-target="#subsubsec\:types"><span class="header-section-number">2.1</span> Types of inductive inference</a>
  <ul class="collapse">
  <li><a href="#inference-to-the-best-explanation" id="toc-inference-to-the-best-explanation" class="nav-link" data-scroll-target="#inference-to-the-best-explanation"><span class="header-section-number">2.1.1</span> Inference to the best explanation</a></li>
  <li><a href="#induction-by-enumeration" id="toc-induction-by-enumeration" class="nav-link" data-scroll-target="#induction-by-enumeration"><span class="header-section-number">2.1.2</span> Induction by enumeration</a></li>
  <li><a href="#inference-from-analogy" id="toc-inference-from-analogy" class="nav-link" data-scroll-target="#inference-from-analogy"><span class="header-section-number">2.1.3</span> Inference from analogy</a></li>
  </ul></li>
  <li><a href="#subsec:PoI" id="toc-subsec:PoI" class="nav-link" data-scroll-target="#subsec\:PoI"><span class="header-section-number">2.2</span> The problem of induction</a></li>
  <li><a href="#the-problem-of-induction-and-statistical-philosophies" id="toc-the-problem-of-induction-and-statistical-philosophies" class="nav-link" data-scroll-target="#the-problem-of-induction-and-statistical-philosophies"><span class="header-section-number">2.3</span> The problem of induction and statistical philosophies</a>
  <ul class="collapse">
  <li><a href="#subsec:Popper" id="toc-subsec:Popper" class="nav-link" data-scroll-target="#subsec\:Popper"><span class="header-section-number">2.3.1</span> The falsification solution</a></li>
  <li><a href="#the-bayesian-solution" id="toc-the-bayesian-solution" class="nav-link" data-scroll-target="#the-bayesian-solution"><span class="header-section-number">2.3.2</span> The Bayesian solution</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-context" class="quarto-section-identifier"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Contextualizing statistics</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p>The general body of researches in mathematical statistics during the last fifteen years is fundamentally a reconstruction of logical rather than mathematical ideas, although the solution of mathematical problems has contributed essentially to this reconstruction.</p>
</blockquote>
<div class="flushright">
<p>— R.A. Fisher, <em>The Logic of Inductive Inference</em></p>
</div>
<p>In <a href="ch1.html" class="quarto-xref"><span>Chapter 1</span></a>, we saw that inductive arguments are such that, even if the premises are true, the conclusions may be false. For example, it might be true that</p>
<dl>
<dt><strong>P</strong>:</dt>
<dd>
<p>up to the current time, <span class="math inline">\(t\)</span>, all observed ravens have been black</p>
</dd>
</dl>
<p>and false that</p>
<dl>
<dt><strong>C</strong>:</dt>
<dd>
<p>All ravens, including those yet to be observed, are black.</p>
</dd>
</dl>
<p>Arguably, most scientific and statistical arguments are inductive in this way: the available data, and modeling assumptions (encoded in premises) do not guarantee the veracity of the inferred scientific theory or statistical hypothesis (the argument’s conclusion). Most inferences to theories or hypotheses <em>go beyond</em> the observations at hand. Scientific laws are sufficiently general, in the sense that they refer not to particular entities or cases, but broad categories. For example, Hubble’s Law of Cosmic Expansion states that <span class="math inline">\(V = h \times d\)</span>, where <span class="math inline">\(V\)</span> is galaxy’s recessional velocity, <span class="math inline">\(h\)</span> is a parameter representing the rate of universe expansion, and <span class="math inline">\(d\)</span> is the galaxy’s distance from a reference galaxy. Hubble’s Law is not only about the relationship between velocity and distance for galaxies that have been observed, but about the relationship between distance and velocity for <em>all</em>, including yet-to-be-observed galaxies. Further, the constant, <span class="math inline">\(h\)</span>, is strictly speaking, an <em>unobservable</em>; it represents “the constant rate of cosmic expansion caused by the stretching of space-time itself” <span class="citation" data-cites="Bagla2009">Bagla (<a href="#ref-Bagla2009" role="doc-biblioref">2009</a>)</span>. <span class="math inline">\(h\)</span> can only be <em>inferred</em> through scientific or statistical methods rather than directly observed.</p>
<p>Inferences to broad generalizations or unobservable entities aren’t particular to the physical sciences. In the social sciences, psychologists are often interested in measuring unobservable psychological traits, called <em>latent variables</em>, such as general intelligence, <span class="math inline">\(g\)</span>, self-esteem, or extroversion. To “measure” latent variables, psychologists must first measure observable variables—e.g., responses to a questionnaire—and have a statistical model describing how the latent variables relate to what was measured.</p>
<p>In this chapter, we study statistical inference as a form of inductive inference. What forms can inductive inference take? What problems arise in attempting to justify inductive inference? How do statistical models contribute to the proper foundation for inductive inference and, by extension, scientific knowledge? How strong are the arguments that justify statistical methodologies? By expanding upon induction and these related questions, we gain a broader and contextualized view of the nature of statistical inference. From there, we will be in the position to begin to evaluate different statistical methodologies.</p>
<section id="subsubsec:types" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="subsubsec:types"><span class="header-section-number">2.1</span> Types of inductive inference</h2>
<p>To better understand inductive inferences, it may be helpful to study different types of inductive inference. Here, we will study three types: inference to the best explanation, induction by enumeration, and inference from analogy. For more information on types of inductive inference, see <span class="citation" data-cites="Vickers2006">Vickers (<a href="#ref-Vickers2006" role="doc-biblioref">2006</a>)</span>.</p>
<section id="inference-to-the-best-explanation" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="inference-to-the-best-explanation"><span class="header-section-number">2.1.1</span> Inference to the best explanation</h3>
<p>Today, Estelle woke up late. She was in a rush to get ready, and quickly grabbed her phone off of the charger on her way out of the house. Soon after, on her way to work, she noticed that her phone battery was only at 20 percent. Oh no! What could be the explanation for why her phone was not charged to (or near) 100 percent? There any many <em>logically possible</em> explanations. Here are a few:</p>
<dl>
<dt><span class="math inline">\(H_1\)</span></dt>
<dd>
<p>Estelle plugged her phone in properly the night before, but, unbeknownst to her, the power went out for a long period of time, and as a result, her phone did not charge.</p>
</dd>
<dt><span class="math inline">\(H_2\)</span></dt>
<dd>
<p>Estelle plugged her phone in properly the night before, but the phone charging cord is faulty and no longer working, and as a result, her phone did not charge.</p>
</dd>
<dt><span class="math inline">\(H_3\)</span></dt>
<dd>
<p>Estelle plugged her phone in properly the night before, but a being from another planet visited her room and unplugged it for most of the night. As a result, her phone did not charge.</p>
</dd>
<dt><span class="math inline">\(H_4\)</span></dt>
<dd>
<p>Estelle, in fact, didn’t plug her phone in properly the night before, and as a result, her phone did not charge.</p>
</dd>
</dl>
<p>Our intuition says that some of these explanations are plausible, and others are not. For example, in the absence of additional information, <span class="math inline">\(H_1\)</span>, <span class="math inline">\(H_2\)</span>, and <span class="math inline">\(H_4\)</span> seem plausible. <span class="math inline">\(H_3\)</span> seems implausible because we have no good reasons to believe that such beings exist or can travel to Earth, and even if they did and could, we have no reason to believe that they have the goal of unplugging our phones.</p>
<p>Now, suppose that Estelle thinks a bit more, and remembers two things: First, she remembers that the digital clock on her stove displayed the correct time on the way out of the house. Second, she remembers that a few other times in the last month, she’s plugged in her phone improperly, and once she secured the connection, her phone charged without issue. This information changes which explanations are plausible. In particular, <span class="math inline">\(H_1\)</span> now becomes much less plausible, and <span class="math inline">\(H_4\)</span> becomes much more plausible. In fact, we might infer that <span class="math inline">\(H_4\)</span> is <em>the best explanation</em> for the fact that the phone is only charged to 20 percent, based on the information at hand.</p>
<p>The reasoning employed in this example is a type of inductive inference<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> called <em>inference to the best explanation</em> (IBE). Generally, IBE might be characterized as the process of “accepting a hypothesis on the grounds that [it] provides [a] better explanation of the given evidence comparing to the other competing hypotheses” <span class="citation" data-cites="Erdenk2015">(<a href="#ref-Erdenk2015" role="doc-biblioref">Erdenk, 2015</a>)</span>. Notice that IBE is clearly not deductive, because there is no requirement that, with limited information, the best explanation is logically entailed by the observed phenomena. In the example above, <span class="math inline">\(H_2\)</span> has not been eliminated on the basis of logical impossibility; rather, it just seems less plausible than <span class="math inline">\(H_4\)</span>.</p>
<p>In science, we often use statistical models to provide explanations for the phenomena that generated the data. Statistical models can help construct such explanations. In many cases, there will be several candidate models for a particular set of data. For example, we might like to explain atmospheric ozone concentration based on certain known conditions, such as temperature, windspeed, humidity, and concentration of certain pollutants, such as sulfur dioxide. Many plausible models could be constructed with respect to these data—some models might include possible pollutants as explanatorily relevant to the variation in atmospheric ozone concentration, while other models might exclude (some of) these pollutants. Statisticians have come up with processes to select a “best” model among the candidates. Some criteria that measure “best”—for example Bayes’ Information Criterion (BIC)—might be thought of as a formalization of inference to the best explanation. That is, among several explanations (models) of the regularities in the data, BIC selects a “best” explanation by balancing goodness of fit with simplicity <span class="citation" data-cites="Faraway2015">Faraway (<a href="#ref-Faraway2015" role="doc-biblioref">2015</a>)</span>.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
</section>
<section id="induction-by-enumeration" class="level3" data-number="2.1.2">
<h3 data-number="2.1.2" class="anchored" data-anchor-id="induction-by-enumeration"><span class="header-section-number">2.1.2</span> Induction by enumeration</h3>
<p>What justifies our knowledge that all electrons have a mass of <span class="math inline">\(9.1 \times 10^{-31}\)</span>g? Or that a hot stove will burn my hand? Or that there will be a full moon on January 18, 2030? The argument for such knowledge is often of the form <span class="citation" data-cites="Norton2002">(<a href="#ref-Norton2002" role="doc-biblioref">Norton, 2002</a>)</span>:</p>
<dl>
<dt><strong>P</strong>:</dt>
<dd>
<p>All <em>observed</em> instances of <span class="math inline">\(A\)</span> have had property <span class="math inline">\(p\)</span>.</p>
</dd>
<dt><strong>C</strong>:</dt>
<dd>
<p>Therefore, <em>all</em> (including unobserved) instances of <span class="math inline">\(A\)</span> will have property <span class="math inline">\(p\)</span>.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
</dd>
</dl>
<p>This type of argument—often called <em>induction by enumeration</em>, or <em>enumerative induction</em>—allows us to generalize from observed regularities to unobserved regularities, and as such, is indispensable to science. Often, induction by enumeration is the only justification that we have for a particular scientific fact, as is the case for the mass of electrons <span class="citation" data-cites="Norton2002">(<a href="#ref-Norton2002" role="doc-biblioref">Norton, 2002</a>)</span>. In other cases, such as those that predict the phases of the moon, physical theories describe the necessary causes that produce the effect that <span class="math inline">\(A\)</span> has property <span class="math inline">\(p\)</span>, and we don’t necessarily need to rely on induction by enumeration directly. But the justification for the physical theories themselves seems to rely on induction by enumeration: how do we know that the laws of planetary motion will hold on January 18, 2030, so that our predictive model will be accurate? We know this because all observed phenomena in the universe (<span class="math inline">\(A\)</span>) have had the property of obeying the laws of planetary motion (<span class="math inline">\(p\)</span>), and infer that <em>all</em> phenomena—including future phenomen—in the universe will obey the laws of planetary motion. That is, we know they will hold because of induction by enumeration!</p>
</section>
<section id="inference-from-analogy" class="level3" data-number="2.1.3">
<h3 data-number="2.1.3" class="anchored" data-anchor-id="inference-from-analogy"><span class="header-section-number">2.1.3</span> Inference from analogy</h3>
<p>A 1978 study of the artificial sweetener saccharin concluded that “saccharin is carcinogenic for the urinary bladder in rats and mice, and most likely is carcinogenic in human beings” <span class="citation" data-cites="Reuber1978">Reuber (<a href="#ref-Reuber1978" role="doc-biblioref">1978</a>)</span>. How might we reason from the premise that saccharin is carcinogenic in rats to the conclusion that it is (likely) carcinogenic in humans? We might argue something like the following:</p>
<dl>
<dt><strong>P1</strong>:</dt>
<dd>
<p>Humans, on the one hand, and rats and mice on the other, share many anatomical, physiological, and genetic properties.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
</dd>
<dt><strong>P2</strong>:</dt>
<dd>
<p>Many of these shared properties are relevant to the development of different types of cancer.</p>
</dd>
<dt><strong>P3</strong>:</dt>
<dd>
<p>Saccharin has been shown to be carcinogenic in rats and mice.</p>
</dd>
<dt><strong>C</strong>:</dt>
<dd>
<p>Therefore, cancer is (likely) carcinogenic in humans.</p>
</dd>
</dl>
<p>This argument might be strengthened by another premise that claims that often in the past, when a result has been demonstrated in rats, it has also been demonstrated in humans <span class="citation" data-cites="ICR2019">(<a href="#ref-ICR2019" role="doc-biblioref"><span>“Animal Research at the ICR,”</span> 2019</a>)</span>. We might interpret such an argument form as an <em>argument from analogy</em>. The general form of an argument from analogy might look something like this:</p>
<dl>
<dt><strong>P1’</strong>:</dt>
<dd>
<p><span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> share properties <span class="math inline">\(p_1,...,p_n\)</span>.</p>
</dd>
<dt><strong>P2’</strong>:</dt>
<dd>
<p><span class="math inline">\(A\)</span> has property <span class="math inline">\(p\)</span> (<span class="math inline">\(p \ne p_i, \,\,\, i = 1,...,n\)</span>).</p>
</dd>
<dt><strong>C’</strong>:</dt>
<dd>
<p>Therefore, <span class="math inline">\(B\)</span> has property <span class="math inline">\(p\)</span>.</p>
</dd>
</dl>
<p>Such an argument is (almost) always categorized as inductive, because it is (almost) never logically inconsistent for <span class="math inline">\(B\)</span> to not have property <span class="math inline">\(p\)</span>. And in fact, to the best of our knowledge as of this writing, <strong>C</strong> is believed to be false; there is “no consistent evidence that saccharin is associated with bladder cancer incidence” <span class="citation" data-cites="ICR2016">(<a href="#ref-ICR2016" role="doc-biblioref"><span>“Artificial Sweeteners and Cancer,”</span> 2016</a>)</span>.</p>
<p>Arguments by analogy are often used in science and statistics, as suggested by the saccharin case above. For another example, in <em>Origin of Species</em>, Darwin draws analogy between domestic selection by breeders and selective process that arises in nature to argue for natural selection as a key mechanism for evolution <span class="citation" data-cites="Norton2018">Norton (<a href="#ref-Norton2018" role="doc-biblioref">2018</a>)</span>.</p>
</section>
</section>
<section id="subsec:PoI" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="subsec:PoI"><span class="header-section-number">2.2</span> The problem of induction</h2>
<p>Common to all types of inductive inference is the fact that the inferences from premises to conclusions are risky: even if the premises are true, the conclusion does not necessarily follow. Consider the following inductive inference:</p>
<dl>
<dt><strong>P</strong>:</dt>
<dd>
<p>In a sample of <span class="math inline">\(n = 100\)</span> University of Colorado Boulder students, 85 students claimed to have some amount of student loan debt.</p>
</dd>
<dt><strong><span class="math inline">\(C^\dagger\)</span></strong>:</dt>
<dd>
<p>Therefore, 85% of all University of Colorado Boulder students have some amount of student loan debt.</p>
</dd>
</dl>
<p>How can we <em>justify</em> this inference from <strong>P</strong> to <span class="math inline">\(C^\dagger\)</span>? More generally, what makes inductive inference a reliable form of inference? Can we come up with an argument for the conclusion that <strong>C</strong>: <em>inductive inferences are justified</em>? Intuitively, we believe that inductive inference <em>is</em> a reliable form of inference, for example, when we believe that the key to our home will work today because it worked yesterday. Many of the conclusions that we draw, including scientific conclusions supported by statistical arguments, rely on inductive inference. However, as philosopher David Hume argued, there is no strong argument for the conclusion that <strong>C</strong>: <em>inductive inferences are justified</em>. That is, there is no rigorous justification for inductive inference. This fact is called <em>the problem of induction</em>. Let’s briefly work through Hume’s argument that leads to the problem of induction.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<p>To gain some insights into Hume’s argument, let’s first consider the ways in which the conclusion of an inductive inference, e.g., <span class="math inline">\(C^\dagger\)</span>, might be wrong. With respect to <span class="math inline">\(C^\dagger\)</span>, it might be the case that the chosen sample is biased in some way; if the sample is biased, then it may be the case that students with student debt had a higher chance (or lower chance) of being chosen for the sample. In that case, we might attempt to take a truly random sample, where every student had the same chance of being chosen. In that case, we could modify our argument:</p>
<dl>
<dt><span class="math inline">\(P^\dagger\)</span></dt>
<dd>
<p>In a <em>random</em> sample of <span class="math inline">\(n = 100\)</span> University of Colorado Boulder students, 85 students claimed to have some amount of student loan debt.</p>
</dd>
<dt><span class="math inline">\(C^\dagger\)</span></dt>
<dd>
<p>Therefore, 85% of all University of Colorado Boulder students have some amount of student loan debt.</p>
</dd>
</dl>
<p>This modification does not solve the issue; still, <span class="math inline">\(C^\dagger\)</span> can be false, while <span class="math inline">\(P^\dagger\)</span> true. Even with a large random sample, it is possible that we are unlucky in the sense that the sample percentage differs greatly from the population percentage. A second issue with our argument is that, in inferring from a sample of University of Colorado Boulder students to the population of all University of Colorado Boulder students, we are making some assumptions about the uniformity of nature across time and space. For example, in choosing a random sample, we are assuming that:</p>
<ul>
<li><p>the parameter <em>percent of University of Colorado Boulder students who have some amount of student debt</em> stays constant, at least across short periods of time; and</p></li>
<li><p>students that we have not observed are similar in the relevant ways (e.g., with respect to finances and student debt) to students that we have observed.</p></li>
</ul>
<p>Taken together, philosophers call generalized versions of these assumptions, the “Uniformity Principle” (UP). The UP states that there is a kind of stability to the world; the parameters that we are attempting to estimate and the laws of nature and regularities that are associated with those parameters stay stable, or themselves change in predictable, lawlike ways. The UP plays a critical role in Hume’s claim that there is no strong justification for inductive inference. First, Hume claims that the UP appears to be assumed in any inductive inference. This claim seems quite plausible: any time that we infer a conclusion based on one of the argument types from section <a href="#subsubsec:types" data-reference-type="ref" data-reference="subsubsec:types">1.1</a>—e.g., that all observed electrons have mass of <span class="math inline">\(9.1 \times 10^{-31}\)</span>g, therefore all electrons (observed and unobserved) will have this mass—we are implicitly assuming the UP. So, inductive inference cannot be truly justified without some justification for the UP. And in fact, the UP seems like the crucial premise in need of justifying.</p>
<p>Once Hume has established the centrality of the UP, he then notes that any justification of the UP must either be deductive or inductive. That is, the UP will either follow necessarily from the premises (deductive); or it will be possible for the premises to be true but for the UP to be false (inductive). As Hume argues, the UP cannot be justified deductively, because it’s negation does not imply a contradiction; there is nothing incoherent about a universe that isn’t uniform across space or time. So, the deductive route will not work. But further, the UP cannot be justified inductively, because any inductive argument justifying the UP would <em>assume</em> the UP itself, and therefore be circular. Thus, according to Hume, our hopes of justifying inductive inference are hopeless: we have failed to justify the UP, which was a necessary condition for justifying inductive inference.</p>
</section>
<section id="the-problem-of-induction-and-statistical-philosophies" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="the-problem-of-induction-and-statistical-philosophies"><span class="header-section-number">2.3</span> The problem of induction and statistical philosophies</h2>
<p>Hume’s problem of induction is well-known among philosophers, and especially philosophers of science. To be sure, it is a philosophical problem <em>about</em> science and statistics; contemporary practicing scientists and statisticians do not often engage directly with this problem. Some might even claim that worries about the justifications for the UP and inductive inference are just philosophical quibbling: the lack of a bedrock justification for induction and the UP, they argue, are not real problems for science, at least in not in practice. But there are good reasons to engage with these issues. First, many scientific and statistical methods were developed as a response to known problems with inductive inference, including Hume’s problem of induction. The developers of these methods often had the explicit goal of making inductive inferences stronger. The frequentist statistician Ronald Fisher (1890 – 1962) contextualized his work as a kind of inductive logic in various places, including in papers titled “Statistical Methods and Scientific Induction” <span class="citation" data-cites="fisher1955">(<a href="#ref-fisher1955" role="doc-biblioref">Fisher, 1955</a>)</span> and “The Logic of Inductive Inference”<span class="citation" data-cites="fisher1935logic">(<a href="#ref-fisher1935logic" role="doc-biblioref">Fisher, 1935</a>)</span>. The first Bayesian analyses—including the work of Reverend Thomas Bayes (1702 – 1761) and Pierre-Simon Laplace’s (1749 – 1827)—were also developed to solve Hume’s problem of induction <span class="citation" data-cites="stigler2018 Clayton2021">(<a href="#ref-Clayton2021" role="doc-biblioref">Clayton, 2021</a>; <a href="#ref-stigler2018" role="doc-biblioref">Stigler, 2018</a>)</span>. Engaging with the problem of induction, along with proposed solutions, may help us gain a deeper understanding of the origins, justifications, and utility of standard statistical methods. In turn, we may then be in a better position to critique and apply them correctly.</p>
<section id="subsec:Popper" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="subsec:Popper"><span class="header-section-number">2.3.1</span> The falsification solution</h3>
<blockquote class="blockquote">
<p>Every experiment may be said to exist only in order to give the facts a chance of disproving the null hypothesis.</p>
</blockquote>
<div class="flushright">
<p>— R.A. Fisher, <em>Design of Experiments</em></p>
</div>
<p>Philosopher of science Karl Popper recognized that Hume’s problem of induction was, in a certain sense, insurmountable. Popper writes:</p>
<blockquote class="blockquote">
<p>Hume, I felt, was perfectly right in pointing out that induction cannot be logically justified. He held that there can be no valid logical arguments allowing us to establish ‘that those instances, of which we have had no experience, resemble those, of which we have had experience’. Consequently ‘even after the observation of the frequent or constant conjunction of objects, we have no reason to draw any inference concerning any object beyond those of which we have had experience’ <span class="citation" data-cites="Popper2010">(<a href="#ref-Popper2010" role="doc-biblioref">Popper, 2010 [1963]</a>)</span>.</p>
</blockquote>
<p>As a result, Popper made no attempt to solve the problem of induction by <em>justifying</em> induction. Rather, he denied that induction was necessary for the proper functioning of science. Instead of generalizing from observations to theories (e.g., scientific laws), Popper believed that science properly functions by first posing the theories, and then testing those theories against particular relevant data. In this way, the proper justificatory structure of science is <em>deductive</em> rather than <em>inductive</em>: a scientific theory <span class="math inline">\(T\)</span>, so Popper claimed, can be conclusively falsified given certain empirical evidence. As an example, consider the theory <span class="math inline">\(T\)</span>: <em>All ravens are black</em>. This theory can be conclusively and deductively falsified with the observation of (at least) one non-black raven. The argument would be:</p>
<dl>
<dt><strong>P1</strong>:</dt>
<dd>
<p>If <span class="math inline">\(T\)</span>: <em>all ravens are black</em>, then any raven observed will be black.</p>
</dd>
<dt><strong>P2</strong>:</dt>
<dd>
<p>A white raven was observed.</p>
</dd>
<dt><strong>C</strong>:</dt>
<dd>
<p>Therefore, <span class="math inline">\(T\)</span> is false.</p>
</dd>
</dl>
<p>This general argument form,</p>
<dl>
<dt><strong>P1</strong>:</dt>
<dd>
<p>If <span class="math inline">\(T\)</span>, then <span class="math inline">\(e\)</span>.</p>
</dd>
<dt><strong>P2</strong>:</dt>
<dd>
<p>Not <span class="math inline">\(e\)</span>.</p>
</dd>
<dt><strong>C</strong>:</dt>
<dd>
<p>Therefore, not <span class="math inline">\(T\)</span>.</p>
</dd>
</dl>
<p>is valid, and therefore, deductive. For Popper, <em>falsification</em>—the process of proposing theories and attempting to refute them—rather than induction, is the real mode of scientific progress.</p>
<p>To be sure, this view has some problems. For one, we might notice that there is an asymmetry between our ability to (1) reject <span class="math inline">\(T\)</span> as false, i.e., when evidence <span class="math inline">\(e\)</span> contradicts <span class="math inline">\(T\)</span>; and (2) accept <span class="math inline">\(T\)</span> as true, i.e., when <span class="math inline">\(e\)</span> does not contradict <span class="math inline">\(T\)</span>. In case (1), practically speaking, most scientific theories and hypotheses are not as easily and clearly falsifiable as <span class="math inline">\(T\)</span>. Consider the health science hypothesis <span class="math inline">\(H\)</span>: <em>A high carbohydrate diet causes an increase in body weight</em>. What evidence would <em>conclusively</em> falsify <span class="math inline">\(H\)</span>? Perhaps, in theory, such evidence exists. We can <em>imagine</em> a world in which any time someone increases their carbohydrate intake for several weeks, they also increase their body weight. In such a world, we might argue:</p>
<dl>
<dt><strong>P1</strong>:</dt>
<dd>
<p>If <span class="math inline">\(H\)</span>: <em>a high carbohydrate diet causes an increase in body weight</em>, then any individual observed eating a high carbohydrate diet will see an increase in body weight.</p>
</dd>
<dt><strong>P2</strong>:</dt>
<dd>
<p>Thom eats a high carbohydrate diet but has <em>not</em> seen an increase in body weight.</p>
</dd>
<dt><strong>C</strong>:</dt>
<dd>
<p>Therefore, <span class="math inline">\(H\)</span> is false.</p>
</dd>
</dl>
<p>However, our imagined world is not the real world; in the real world, diet is complicated. There are many other factors that also influence body weight. Strict falsification is much more difficult to attain. Statistical methods attempt to control for these other factors—as well as random variation—to isolate the effect of diet on body weight. But even then, do we know we controlled for all of the right factors? How do we know that we did not leave something out, or that random variation, rather than diet, led us to reject <span class="math inline">\(H\)</span>? Conclusive falsification seems, in practice at least, unattainable. It is not clear exactly what evidence we could practically attain that would allow us to conclusively falsify most real-world scientific hypotheses. As we will see in <span class="quarto-unresolved-ref">?sec-frequentist</span>, <span class="quarto-unresolved-ref">?sec-Bayesian</span>, and <span class="quarto-unresolved-ref">?sec-causation</span>, statistical philosophies, including causal inference, can help us make inferences and practical decisions in the absence of conclusive falsification.</p>
<p>In case (2), <span class="math inline">\(e\)</span> being broadly consistent with <span class="math inline">\(T\)</span> does not confirm <span class="math inline">\(T\)</span>, because <span class="math inline">\(e\)</span> will be consistent with other (in fact, infinitely many other) theories, <span class="math inline">\(T_i\)</span>, each of which is not equivalent to <span class="math inline">\(T\)</span>. Yet another observed black raven does not confirm <span class="math inline">\(T\)</span>, and there are many other theories consistent with new observation (e.g., <span class="math inline">\(T_1\)</span>: <em>ravens are <span class="math inline">\(60\%\)</span> black and <span class="math inline">\(40\%\)</span> white</em>). Popper’s solution to this problem is to introduce the notion of corroboration. A theory <span class="math inline">\(T\)</span> is <em>corroborated</em> by <span class="math inline">\(e\)</span> if <span class="math inline">\(e\)</span> were produced by a “severe test”. By a “severe test”, Popper means “tests that would probably have falsified a claim if false” <span class="citation" data-cites="Mayo2018">(<a href="#ref-Mayo2018" role="doc-biblioref">Mayo, 2018</a>)</span>. Note that corroboration is not strict confirmation, if by ‘confirmation’ one means <em>conclusively true</em>. Instead, corroboration is a building up of support for <span class="math inline">\(T\)</span>, through the right kinds of probes.</p>
<p>If one is familiar with the statistical hypothesis testing developed by Ronald Fisher, Jerzy Neyman (1894 – 1981), and Egon Pearson (1895 – 1980), Popper’s logic of conjecture and refutation should not be entirely foreign.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> In statistical hypothesis testing, and in Popper’s falsification paradigm, a hypothesis is put forward, and a statistical procedure is conducted to attempt to falsify it. Interestingly, classical frequentist hypothesis testing starts and ends with conjecture and refutation; there was no formal method for corroboration or so-called severe testing. More recently, philosophers Deborah Mayo and Aris Spanos developed a set of statistical tools that formalize the notion of a severe test, which, when used correctly, can help corroborate hypotheses <span class="citation" data-cites="mayo_spanos_2011b Mayo2018">(<a href="#ref-Mayo2018" role="doc-biblioref">Mayo, 2018</a>; <a href="#ref-mayo_spanos_2011b" role="doc-biblioref">Mayo &amp; Spanos, 2011</a>)</span>. In <span class="quarto-unresolved-ref">?sec-frequentist</span>, we will study the statistical procedures that Fisher, Neyman, Pearson, Mayo, and Spanos have developed to deal with messy, real-world scientific theories and hypotheses.</p>
<p>So, do falsification and hypothesis testing succeed in solving the problem of induction? We will not be able to adequately address this question until <span class="quarto-unresolved-ref">?sec-frequentist</span>. But, as we will see, under the statistical assumptions posed in a statistical model, hypothesis testing provides a framework for quantifying uncertainty in our conclusions and behaviors by controlling error rates over the long run. This error control represents an important step forward in strengthening inductive inference: if the modeling assumptions are (roughly) met, we know how often we will be in error in the long run. While this paradigm does make explicit and precise statements about probabilities, it still assumes the UP—i.e., by making claims about “the long run”. But, as we saw in section <a href="#subsec:PoI" data-reference-type="ref" data-reference="subsec:PoI">1.2</a>, the UP cannot be justified without circularity. So, in failing to avoid the UP, strictly speaking, these statistical method has failed to circumvent the problem of induction. Nevertheless, these methods provide some guidance for belief and action under uncertainty.</p>
</section>
<section id="the-bayesian-solution" class="level3" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="the-bayesian-solution"><span class="header-section-number">2.3.2</span> The Bayesian solution</h3>
<p>The most popular alternative to Popper’s falsificationist framework—and falsificationist statistical methods like hypothesis testing—is called <em>probabilism</em>. Probabilism is the view that conclusions, theories, and hypotheses can be assigned a degree of support through the use of probability theory <span class="citation" data-cites="Mayo2018">(<a href="#ref-Mayo2018" role="doc-biblioref">Mayo, 2018</a>)</span>. Probabilism assigns theories a number between zero and one, which represents, roughly, how plausible the theory is. Perhaps we have the following argument:</p>
<p>Over one million ravens have been observed, and all have been black.</p>
<p>Therefore, <em>all ravens are black</em>. Intuitively, <span class="math inline">\(T\)</span> has strong support. Probabilism might assign <span class="math inline">\(T\)</span> a number close to one. It is <em>possible</em> that <span class="math inline">\(\neg T\)</span>: <em>some ravens are not black</em>. But given the lack of evidence, <span class="math inline">\(\neg T\)</span> would be assigned a low number, close to zero.</p>
<p>Various attempts have been made to formalize probabilism as a theory of inductive logic <span class="citation" data-cites="Bayese_Price_1763 cox1946probability carnap1962logical">(<a href="#ref-Bayese_Price_1763" role="doc-biblioref">Bayes &amp; Price, 1763</a>; <a href="#ref-carnap1962logical" role="doc-biblioref">Carnap, 1962</a>; <a href="#ref-cox1946probability" role="doc-biblioref">Cox, 1946</a>)</span>. The most famous form of probabilism, with the closest connection to statistical practice, is Bayesian probabilism. Bayesian probabilism makes use of Bayes’ theorem to update probabilities assigned to theories based on observed evidence. For example, suppose that we start out by assigning <span class="math inline">\(H\)</span>: <em>a high carbohydrate diet causes an increase in body weight</em> a probability of <span class="math inline">\(0.3\)</span>. Nutrition researchers studying this hypothesis conduct a study and find that <span class="math inline">\(e\)</span>: <em>on average, participants on a high carbohydrate diet gained 3 pounds more than those on a low carbohydrate diet</em>. Suppose that the probability of observing <span class="math inline">\(e\)</span> if <span class="math inline">\(H\)</span> were true is <span class="math inline">\(P(e \, | \, H) = 0.8\)</span>, and the probability of <span class="math inline">\(E\)</span> if <span class="math inline">\(H\)</span> were false is <span class="math inline">\(P(e  \,| \, \neg H) = 0.4\)</span>. Bayes’ theorem states that<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> <span class="math display">\[
\begin{aligned}
P(H \,|\, e) &amp;= \frac{P(e \, | \, H)P(H)}{P(e \,|\, H)P(H) + P(e \,| \,\neg H)P(\neg H)}  \\
&amp;= \frac{(0.8)(0.3)}{(0.8)(0.3) + (0.4)(0.7)} \approx 0.46.
\end{aligned}
\]</span></p>
<p>Thus, the updated probability of <span class="math inline">\(H\)</span>, based on observing <span class="math inline">\(e\)</span>, is higher. Probabilism aids inductive logic, in the sense that it provides a number that quantifies the strength of the conclusion (i.e., the theory or hypothesis) given the premises (evidence and assumptions).</p>
<p>Probabilism also has its problems. Many prominent philosophers and statisticians—Popper and Fisher among them—are vehemently opposed to the use of probability to confirm hypotheses. Popper argued that the degree of confirmation that <span class="math inline">\(e\)</span> confers on <span class="math inline">\(H\)</span> is not the same as the probability of <span class="math inline">\(H\)</span> given <span class="math inline">\(e\)</span> <span class="citation" data-cites="popper2005logic Mayo2018">(<a href="#ref-Mayo2018" role="doc-biblioref">Mayo, 2018</a>; <a href="#ref-popper2005logic" role="doc-biblioref">Popper, [1959] 2005</a>)</span>. <span class="citation" data-cites="Chapman2015">Chapman (<a href="#ref-Chapman2015" role="doc-biblioref">2015</a>)</span> argues that, contrary to the starting point of probabilisim, <em>probability</em> is not equipped to extend deductive logic to reasoning about <em>plausibility</em> (i.e., uncertain reasoning). Fisher wrote that “probability is a ratio of frequencies, and about the frequencies of such [hypotheses] we can know nothing whatever” <span class="citation" data-cites="Fisher1922">Fisher (<a href="#ref-Fisher1922" role="doc-biblioref">1922</a>)</span>.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> A primary problem for these thinkers is that probabilism relies on an epistemic interpretation of probability. Such an interpretation allows for probabilities to be assigned to fixed, non-repeatable features of the world. It’s not clear how such probability assignments arise. How did we come up with <span class="math inline">\(P(H) = 0.3\)</span>? It is not tied to any repeatable process. It seems like we just made it up! For those that reject Bayesian probabilism, all probabilities must arise from empirical phenomena, and ought to be reserved for events that are (at least theoretically) repeatable.</p>
<p>As with falsification and frequentist hypothesis testing, we might ask: does Bayesian probabilism provide a solution to the problem of induction? Again, we will not be able to adequately address this question until we study Bayesian inference in more depth, in <span class="quarto-unresolved-ref">?sec-Bayesian</span>. Bayesian inference provides a formal framework for assessing how evidence bears on different hypotheses. Specifically, under the statistical assumptions, Bayesian inference assigns a “plausibility score”, in the form of a probability, to each hypothesis, e.g., <span class="math inline">\(P(H \,|\, e)  \approx 0.46.\)</span>. These probability assignments represent an important step forward in strengthening inductive inference: if the modeling assumptions are (roughly) met then the probabilities of various hypotheses are interpreted as our degrees of belief in those hypotheses. The higher the probability, the more likely the hypothesis is to be true. While it does make explicit and precise statements about degrees of belief in various hypotheses, it still assumes that the future will be roughly like the past, i.e., it assumes the UP. But, as we saw in section <a href="#subsec:PoI" data-reference-type="ref" data-reference="subsec:PoI">1.2</a>, the UP cannot be justified without circularity. So, in failing to avoid the UP, this statistical method has failed to circumvent the problem of induction. Nevertheless, Bayesian methods provide some guidance for belief and action under uncertainty.<br>
<br>
<br>
Although, strictly speaking, the statistical inference methods described in this chapter do not <em>solve</em> the problem of induction, they go a long way toward placing induction on a stronger foundation. These methods are also quite different from each other. One champions falsification and refutation, and the other assigns probabilities directly to theories and hypotheses. What allows for these differences? Which one provides a stronger foundation for inductive inference? Are there other statistical inference paradigms that do better? The goal of the next few chapters will be to answer these questions.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-ICR2019" class="csl-entry" role="listitem">
Animal research at the ICR. (2019). In <em>The Institute of Cancer Research</em>. <a href="https://www.icr.ac.uk/our-research/about-our-research/animal-research/animal-research-at-the-icr">https://www.icr.ac.uk/our-research/about-our-research/animal-research/animal-research-at-the-icr</a>
</div>
<div id="ref-ICR2016" class="csl-entry" role="listitem">
Artificial sweeteners and cancer. (2016). In <em>National Cancer Institute</em>. <a href="https://www.cancer.gov/about-cancer/causes-prevention/risk/diet/artificial-sweeteners-fact-sheet">https://www.cancer.gov/about-cancer/causes-prevention/risk/diet/artificial-sweeteners-fact-sheet</a>
</div>
<div id="ref-Bagla2009" class="csl-entry" role="listitem">
Bagla, J. S. (2009). Hubble, hubble?s law and the expanding universe. <em>Resonance</em>, <em>14</em>(3), 216?225. <a href="https://doi.org/10.1007/s12045-009-0022-8">https://doi.org/10.1007/s12045-009-0022-8</a>
</div>
<div id="ref-Bayese_Price_1763" class="csl-entry" role="listitem">
Bayes, T., &amp; Price, R. (1763). LII. An essay towards solving a problem in the doctrine of chances. By the late rev. Mr. Bayes, f. R. S. Communicated by mr. Price, in a letter to john canton, a. M. F. R. s. <em>Philosophical Transactions of the Royal Society of London</em>, <em>53</em>, 370?418. <a href="https://doi.org/10.1098/rstl.1763.0053">https://doi.org/10.1098/rstl.1763.0053</a>
</div>
<div id="ref-Bryda2013" class="csl-entry" role="listitem">
Bryda, E. C. (2013). The mighty mouse: The impact of rodents on advances in biomedical research. In <em>Missouri medicine</em>. Journal of the Missouri State Medical Association. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3987984/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3987984/</a>
</div>
<div id="ref-carnap1962logical" class="csl-entry" role="listitem">
Carnap, R. (1962). <em>Logical foundations of probability</em> (Vol. 2). Citeseer.
</div>
<div id="ref-Chapman2015" class="csl-entry" role="listitem">
Chapman, D. (2015). <em>Probability theory does not extend logic</em>. <a href="https://metarationality.com/probability-and-logic">https://metarationality.com/probability-and-logic</a>
</div>
<div id="ref-Clayton2021" class="csl-entry" role="listitem">
Clayton, A. (2021). <em>Bernoulli’s fallacy: Statistical illogic and the crisis of modern science</em>. Columbia University Press.
</div>
<div id="ref-cox1946probability" class="csl-entry" role="listitem">
Cox, R. T. (1946). Probability, frequency and reasonable expectation. <em>American Journal of Physics</em>, <em>14</em>(1), 1–13.
</div>
<div id="ref-Erdenk2015" class="csl-entry" role="listitem">
Erdenk, E. A. (2015). Two tokens of the inference to the best explanation: No-miracle argument and the selectionist explanation. <em>Beytulhikme An International Journal of Philosophy</em>, <em>5</em>(1), 31. <a href="https://doi.org/10.18491/bijop.59053">https://doi.org/10.18491/bijop.59053</a>
</div>
<div id="ref-Faraway2015" class="csl-entry" role="listitem">
Faraway, J. James. (2015). <em>Linear models with r</em>. CRC Press, Taylor &amp; Francis Group.
</div>
<div id="ref-fisher1955" class="csl-entry" role="listitem">
Fisher, R. (1955). Statistical methods and scientific induction. <em>Journal of the Royal Statistical Society Series B: Statistical Methodology</em>, <em>17</em>(1), 69–78.
</div>
<div id="ref-Fisher1922" class="csl-entry" role="listitem">
Fisher, R. A. (1922). On the mathematical foundations of theoretical statistics. <em>Philosophical Transactions of the Royal Society</em>, 309?368. <a href="https://doi.org/10.1007/978-1-4612-0919-5_2">https://doi.org/10.1007/978-1-4612-0919-5_2</a>
</div>
<div id="ref-fisher1935logic" class="csl-entry" role="listitem">
Fisher, R. A. (1935). The logic of inductive inference. <em>Journal of the Royal Statistical Society</em>, <em>98</em>(1), 39–82.
</div>
<div id="ref-henderson2018" class="csl-entry" role="listitem">
Henderson, L. (2018). The problem of induction. In <em>Stanford Encyclopedia of Philosophy</em>. <a href="https://plato.stanford.edu/entries/induction-problem/#Bib">https://plato.stanford.edu/entries/induction-problem/#Bib</a>
</div>
<div id="ref-Mayo2018" class="csl-entry" role="listitem">
Mayo, D. G. (2018). <em>Statistical inference as severe testing: How to get beyond the statistics wars</em>. Cambridge University Press.
</div>
<div id="ref-mayo_spanos_2011b" class="csl-entry" role="listitem">
Mayo, D. G., &amp; Spanos, A. (2011). The error-statistical philosophy. In <em>Error and inference: Recent exchanges on experimental reasoning, reliability, and the objectivity and rationality of science</em>. Cambridge University Press.
</div>
<div id="ref-Norton2002" class="csl-entry" role="listitem">
Norton, J. D. (2002). A survey of inductive generalization. In <em>A Survey of Inductive Generalization</em>. University of Pittsburg. <a href="http://www.pitt.edu/~jdnorton/papers/Survey_ind_gen.pdf">http://www.pitt.edu/~jdnorton/papers/Survey_ind_gen.pdf</a>
</div>
<div id="ref-Norton2018" class="csl-entry" role="listitem">
Norton, J. D. (2018). <em>The material theory of induction</em>.
</div>
<div id="ref-Okasha2016" class="csl-entry" role="listitem">
Okasha, S. (2016). <em>Philosophy of science: A very short introduction</em>. Oxford University Press.
</div>
<div id="ref-popper2005logic" class="csl-entry" role="listitem">
Popper, K. ([1959] 2005). <em>The logic of scientific discovery</em>. Routledge.
</div>
<div id="ref-Popper2010" class="csl-entry" role="listitem">
Popper, K. R. (2010 [1963]). <em>Conjectures and refutations: The growth of scientific knowledge</em>. Routledge.
</div>
<div id="ref-Reuber1978" class="csl-entry" role="listitem">
Reuber, M. D. (1978). Carcinogenicity of saccharin. In <em>Environmental health perspectives</em>. U.S. National Library of Medicine. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1637197/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1637197/</a>
</div>
<div id="ref-stigler2018" class="csl-entry" role="listitem">
Stigler, S. M. (2018). Richard price, the first bayesian. <em>Statistical Science</em>, (1).
</div>
<div id="ref-Vickers2006" class="csl-entry" role="listitem">
Vickers, J. (2006). The problem of induction. In <em>Stanford Encyclopedia of Philosophy</em>. <a href="https://stanford.library.sydney.edu.au/archives/sum2016/entries/induction-problem/#CarIndLog">https://stanford.library.sydney.edu.au/archives/sum2016/entries/induction-problem/#CarIndLog</a>
</div>
</div>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Note that some philosophers do not classify IBE as a type of induction (or deduction); such philosophers carve up the space of non-deductive arguments differently than we have here, to leave space for IBE as its own type of inference. See Chapter 2 of <span class="citation" data-cites="Okasha2016">Okasha (<a href="#ref-Okasha2016" role="doc-biblioref">2016</a>)</span> for more details.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Arguably, using BIC for <em>explanation</em> rather than <em>prediction</em> would require that we know something about the extent to which each input variable in the statistical model is causally related to the output variable. BIC does not, on its own, select for causal relationships, and such relationships are typically what is desired in an explanation.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>A more modest version of the conclusion of enumerative induction is (C) Therefore, <em>the next</em> unobserved instance of <span class="math inline">\(A\)</span> will have property <span class="math inline">\(p\)</span>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>See <span class="citation" data-cites="Bryda2013">Bryda (<a href="#ref-Bryda2013" role="doc-biblioref">2013</a>)</span> for evidence of the claim that there are such similarities.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>My explanation of Hume’s argument relies on <span class="citation" data-cites="henderson2018">Henderson (<a href="#ref-henderson2018" role="doc-biblioref">2018</a>)</span>.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Hypothesis testing was developed separately by Fisher, on the one hand, and Neyman and Pearson on the other. The version often taught is a blend of these two methods.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>If this formulation of Bayes’ theorem does not look familiar to you, do not worry. We will discuss Bayes’ theorem in detail in <span class="quarto-unresolved-ref">?sec-Bayesian</span>.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>We will consider issues related to interpretations of probability—e.g., whether probability <em>just is</em> a ratio of frequencies or not—in <span class="quarto-unresolved-ref">?sec-probability</span>.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./ch1.html" class="pagination-link" aria-label="Philosophy, statistics, and the philosophy of statistics">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Philosophy, statistics, and the philosophy of statistics</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->




</body></html>