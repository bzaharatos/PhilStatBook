%%%%%%%%%%%%%%%%
% NEW CHAPTER! %
%%%%%%%%%%%%%%%%

\chapter{Contextualizing statistics}
\label{chapter:context}
\begin{quote}
The general body of researches in mathematical statistics during the last fifteen years is fundamentally a reconstruction of logical rather than mathematical ideas, although the solution of mathematical problems has contributed essentially to this reconstruction.
\end{quote}
\begin{flushright}
— R.A. Fisher, \textit{The Logic of Inductive Inference}
\end{flushright}


In \cref{chapter:intro}, we saw that inductive arguments are such that, even if the premises are true, the conclusions may be false. For example, it might be true that
\begin{description}
	\item[{\bf P}:] up to the current time, $t$, all observed ravens have been black
\end{description}
 and false that 
 \begin{description}
	\item[{\bf C}:] All ravens, including those yet to be observed, are black.
\end{description}
Arguably, most scientific and statistical arguments are inductive in this way: the available data, and modeling assumptions (encoded in premises) do not guarantee the veracity of the inferred scientific theory or statistical hypothesis (the argument's conclusion). Most inferences to theories or hypotheses {\it go beyond} the observations at hand. Scientific laws are sufficiently general, in the sense that they refer not to particular entities or cases, but broad categories. For example, Hubble's Law of Cosmic Expansion states that $V = h \times d$, where $V$ is galaxy's recessional velocity, $h$ is a parameter representing the rate of universe expansion, and $d$ is the galaxy's distance from a reference galaxy. Hubble's Law is not only about the relationship between velocity and distance for galaxies that have been observed, but about the relationship between distance and velocity for {\it all}, including yet-to-be-observed galaxies. Further, the constant, $h$, is strictly speaking, an {\it unobservable}; it represents ``the constant rate of cosmic expansion caused by the stretching of space-time itself'' \citet{Bagla2009}. $h$ can only be {\it inferred} through scientific or statistical methods rather than directly observed.

Inferences to broad generalizations or unobservable entities aren't particular to the physical sciences. In the social sciences, psychologists are often interested in measuring unobservable psychological traits, called {\it latent variables}, such as general intelligence, $g$, self-esteem, or extroversion. To ``measure'' latent variables, psychologists must first measure observable variables---e.g., responses to a questionnaire---and have a statistical model describing how the latent variables relate to what was measured. 

In this chapter, we study statistical inference as a form of inductive inference. What forms can inductive inference take? What problems arise in attempting to justify inductive inference? How do statistical models contribute to the proper foundation for inductive inference and, by extension, scientific knowledge? How strong are the arguments that justify statistical methodologies? %Do any of the competing statistical methodologies provide solution to the longstanding philosophical problem of induction? %We will explore these questions in Chapter \ref{chapter:context}.
By expanding upon induction and these related questions, we gain a broader and contextualized view of the nature of statistical inference. From there, we will be in the position to begin to evaluate different statistical methodologies.


%Interesting mention of induction WRT prediction and explanation on 338 of Curd (phil sci reader). We could connect this back to the intro chapter mention of regression: only prediction counts as inductive evidence, not explanation? That's interesting...


%Basic overview: statistical inference can be understood as a type of inductive inference. Describe the problem of induction, and put forth statistics as a potential set of solutions to the problem. I think it is reasonable to have this chapter be short, and try to avoid issues about interpretations of probability, which will be covered in the next chapter.

\section{Types of inductive inference}
\label{subsubsec:types}

To better understand inductive inferences, it may be helpful to study different types of inductive inference. Here, we will study three types: inference to the best explanation, induction by enumeration, and inference from analogy. For more information on types of inductive inference, see \citet{Vickers2006}.
%https://stanford.library.sydney.edu.au/archives/sum2016/entries/induction-problem/#CarIndLog
%From SEP on Problem of induction: "Carnap's taxonomy of the varieties of inductive inference (LFP 207f) may help to appreciate the complexity of the contemporary concept.
%
%Direct inference typically infers the relative frequency of a trait in a sample from its relative frequency in the population from which the sample is drawn.
%Predictive inference is inference from one sample to another sample not overlapping the first. This, according to Carnap, is the most important and fundamental kind of inductive inference? (LFP, 207). It includes the special case, known as singular predictive inference, in which the second sample consists of just one individual.
%Inference by analogy is inference from the traits of one individual to those of another on the basis of traits that they share.
%Inverse inference infers something about a population on the basis of premises about a sample from that population.
%Universal inference, mentioned in the opening sentence of this article, is inference from a sample to a hypothesis of universal form."


\subsection{Inference to the best explanation}
Today, Estelle woke up late. She was in a rush to get ready, and quickly grabbed her phone off of the charger on her way out of the house. Soon after, on her way to work, she noticed that her phone battery was only at 20 percent. Oh no! What could be the explanation for why her phone was not charged to (or near) 100 percent? There any many {\it logically possible} explanations. Here are a few:
\begin{description}
	\item[$H_1$] Estelle plugged her phone in properly the night before, but, unbeknownst to her, the power went out for a long period of time, and as a result, her phone did not charge.
	\item[$H_2$] Estelle plugged her phone in properly the night before, but the phone charging cord is faulty and no longer working, and as a result, her phone did not charge. 
	\item[$H_3$] Estelle plugged her phone in properly the night before, but a being from another planet visited her room and unplugged it for most of the night. As a result, her phone did not charge.
	\item [$H_4$] Estelle, in fact, didn't plug her phone in properly the night before, and as a result, her phone did not charge.
\end{description}
Our intuition says that some of these explanations are plausible, and others are not. For example, in the absence of additional information, $H_1$, $H_2$, and $H_4$ seem plausible. $H_3$ seems implausible because we have no good reasons to believe that such beings exist or can travel to Earth, and even if they did and could, we have no reason to believe that they have the goal of unplugging our phones. 

Now, suppose that Estelle thinks a bit more, and remembers two things: First, she remembers that the digital clock on her stove displayed the correct time on the way out of the house. Second, she remembers that a few other times in the last month, she's plugged in her phone improperly, and once she secured the connection, her phone charged without issue. This information changes which explanations are plausible. In particular, $H_1$ now becomes much less plausible, and $H_4$ becomes much more plausible. In fact, we might infer that $H_4$ is {\it the best explanation} for the fact that the phone is only charged to 20 percent, based on the information at hand.

The reasoning employed in this example is a type of inductive inference\footnote{Note that some philosophers do not classify IBE as a type of induction (or deduction); such philosophers carve up the space of non-deductive arguments differently than we have here, to leave space for IBE as its own type of inference. See Chapter 2 of \citet{Okasha2016} for more details.} called {\it inference to the best explanation} (IBE). Generally, IBE might be characterized as the process of ``accepting a hypothesis on the grounds that [it] provides [a] better explanation of the given evidence comparing to the other competing hypotheses'' \citep{Erdenk2015}. Notice that IBE is clearly not deductive, because there is no requirement that, with limited information, the best explanation is logically entailed by the observed phenomena. In the example above, $H_2$ has not been eliminated on the basis of logical impossibility; rather, it just seems less plausible than $H_4$.

In science, we often use statistical models to provide explanations for the phenomena that generated the data.  Statistical models can help construct such explanations. In many cases, there will be several candidate models for a particular set of data. For example, we might like to explain atmospheric ozone concentration based on certain known conditions, such as temperature, windspeed, humidity, and concentration of certain pollutants, such as sulfur dioxide. Many plausible models could be constructed with respect to these data---some models might include possible pollutants as explanatorily relevant to the variation in atmospheric ozone concentration, while other models might exclude (some of) these pollutants. Statisticians have come up with processes to select a ``best'' model among the candidates. Some criteria that measure ``best''---for example Bayes' Information Criterion (BIC)---might be thought of as a formalization of inference to the best explanation. That is, among several explanations (models) of the regularities in the data, BIC selects a ``best'' explanation by balancing goodness of fit with simplicity \citet{Faraway2015}.\footnote{Arguably, using BIC for {\it explanation} rather than {\it prediction} would require that we know something about the extent to which each input variable in the statistical model is causally related to the output variable. BIC does not, on its own, select for causal relationships, and such relationships are typically what is desired in an explanation. }

\subsection{Induction by enumeration}
What justifies our knowledge that all electrons have a mass of $9.1 \times 10^{-31}$g? Or that a hot stove will burn my hand? Or that there will be a full moon on January 18, 2030? The argument for such knowledge is often of the form \citep{Norton2002}:

\begin{description}
	\item[{\bf P}:] All {\it observed} instances of $A$ have had property $p$.
	\item[{\bf C}:] Therefore, {\it all} (including unobserved) instances of $A$ will have property $p$.\footnote{A more modest version of the conclusion of enumerative induction is (C) Therefore, {\it the next} unobserved instance of $A$ will have property $p$.}
\end{description}

This type of argument---often called {\it induction by enumeration}, or {\it enumerative induction}---allows us to generalize from observed regularities to unobserved regularities, and as such, is indispensable to science. Often, induction by enumeration is the only justification that we have for a particular scientific fact, as is the case for the mass of electrons \citep{Norton2002}. In other cases, such as those that predict the phases of the moon, physical theories describe the necessary causes that produce the effect that $A$ has property $p$, and we don't necessarily need to rely on induction by enumeration directly. But the justification for the physical theories themselves seems to rely on induction by enumeration: how do we know that the laws of planetary motion will hold on January 18, 2030, so that our predictive model will be accurate? We know this because all observed phenomena in the universe ($A$) have had the property of obeying the laws of planetary motion ($p$), and infer that {\it all} phenomena---including future phenomen---in the universe will obey the laws of planetary motion. That is, we know they will hold because of induction by enumeration!



\subsection{Inference from analogy}
A 1978 study of the artificial sweetener saccharin concluded that ``saccharin is carcinogenic for the urinary bladder in rats and mice, and most likely is carcinogenic in human beings'' \citet{Reuber1978}. How might we reason from the premise that saccharin is carcinogenic in rats to the conclusion that it is (likely) carcinogenic in humans? We might argue something like the following:

\begin{description}
	\item[{\bf P1}:] Humans, on the one hand, and rats and mice on the other, share many anatomical, physiological, and genetic properties.\footnote{See \citet{Bryda2013} for evidence of the claim that there are such similarities.}
	\item[{\bf P2}:] Many of these shared properties are relevant to the development of different types of cancer.
	\item[{\bf P3}:] Saccharin has been shown to be carcinogenic in rats and mice.
	\item[{\bf C}:] Therefore, cancer is (likely) carcinogenic in humans.
\end{description}
This argument might be strengthened by another premise that claims that often in the past, when a result has been demonstrated in rats, it has also been demonstrated in humans \citep{ICR2019}. We might interpret such an argument form as an {\it argument from analogy}. The general form of an argument from analogy might look something like this:
\begin{description}
	\item[{\bf P1'}:] $A$ and $B$ share properties $p_1,...,p_n$.
	\item[{\bf P2'}:] $A$ has property $p$ ($p \ne p_i, \,\,\, i = 1,...,n$).
	\item[{\bf C'}:] Therefore, $B$ has property $p$.
\end{description}
Such an argument is (almost) always categorized as inductive, because it is (almost) never logically inconsistent for $B$ to not have property $p$. And in fact, to the best of our knowledge as of this writing, {\bf C} is believed to be false; there is ``no consistent evidence that saccharin is associated with bladder cancer incidence'' \citep{ICR2016}. 

Arguments by analogy are often used in science and statistics, as suggested by the saccharin case above. For another example, in {\it Origin of Species}, Darwin draws analogy between domestic selection by breeders and selective process that arises in nature to argue for natural selection as a key mechanism for evolution \citet{Norton2018}. 

%SAMPLING AS ANALOGY: https://plato.stanford.edu/entries/reasoning-analogy/#IndJus

%Also: ANALOGY GETTING US TO PRIORS: Salmon Rationality and Objectivity in Science (Curd)


\section{The problem of induction}
\label{subsec:PoI}
Common to all types of inductive inference is the fact that the inferences from premises to conclusions are risky: even if the premises are true, the conclusion does not necessarily follow. Consider the following inductive inference:

\begin{description}
\item[{\bf P}:] In a sample of $n = 100$ University of Colorado Boulder students, 85 students claimed to have some amount of student loan debt.
\item[{\bf $C^\dagger$}:] Therefore, 85\% of all University of Colorado Boulder students have some amount of student loan debt. 
\end{description}


How can we {\it justify} this inference from {\bf P} to $C^\dagger$? More generally, what makes inductive inference a reliable form of inference? Can we come up with an argument for the conclusion that {\bf C}: {\it inductive inferences are justified}? Intuitively, we believe that inductive inference {\it is} a reliable form of inference, for example, when we believe that the key to our home will work today because it worked yesterday. Many of the conclusions that we draw, including scientific conclusions supported by statistical arguments, rely on inductive inference. However, as philosopher David Hume argued, there is no strong argument for the conclusion that {\bf C}: {\it inductive inferences are justified}. That is, there is no rigorous justification for inductive inference. This fact is called {\it the problem of induction}. Let's briefly work through Hume's argument that leads to the problem of induction.\footnote{My explanation of Hume's argument relies on \citet{henderson2018}.} %As  statisticians and data scientists (and more generally, as human beings who might care to draw true and reliable conclusions about the world), we should engage with the problem of induction: it concerns the veracity and reliability of the methods we use to learn abou the world.
%That argument might looks something like this:
%
%\begin{enumerate}
%\item[{\bf Argument Justifying Inductive Inference}]
%\begin{enumerate}
%\item[$P1$] ...
%\item[$P2$] ...
%\item[] ...
%\item[$Pn$] ...
%\item[$C$] {\it inductive inferences are justified}
%\end{enumerate}
%\end{enumerate}



%To answer these questions, let's first consider how we might go about justifying {\it deductive reasoning}. Consider, again, {\bf Argument \#1} from Chapter \ref{chapter:intro}:
%
%\begin{enumerate}
%\item[{\bf Argument \#1}]
%\begin{enumerate}
%\item[P1] On any given day, if it is raining, then Newman will not go on his postal route.
%\item[P2] Today, it is raining.
%\item[$C^*$] So, today, Newman will not go on his postal route.
%\end{enumerate}
%\end{enumerate}
%One option for justifying a deductive inference such as this one is to suggest that the information contained in the conclusion, $C$, is already contained in the premises $P1$ and $P2$; that is, $C$ just rearranges the information in $P1$ and $P2$.\footnote{We should note that some disagree with this analysis. See \citet{Haack1976}.} So, deductive inference is justified, and an argument for it might be: All conclusions 

%Such a move will not work for induction, for the simple fact that the conclusion of a deductive argument contains information {\it not contained in the premises}; in particular, notice that $C^\dagger$ can certainly be false even if $P$ is true. Would strengthening the argument work? Suppose that we sampled not $n = 100$ students, but $n = 1,000$ students, and found that $850$ had some form of student loan debt. Then does the $C^\dagger$ follow? Unfortunately not. It is still possible that $C^\dagger$ is false.\footnote{Unless we sample the entire population, in which case the conclusion would just be a restatement of the premise.} 
To gain some insights into Hume's argument, let's first consider the ways in which the conclusion of an inductive inference, e.g., $C^\dagger$, might be wrong. With respect to $C^\dagger$, it might be the case that the chosen sample is biased in some way; if the sample is biased, then it may be the case that students with student debt had a higher chance (or lower chance) of being chosen for the sample. In that case, we might attempt to take a truly random sample, where every student had the same chance of being chosen. In that case, we could modify our argument:


\begin{description}
\item[$P^\dagger$] In a {\it random} sample of $n = 100$ University of Colorado Boulder students, 85 students claimed to have some amount of student loan debt.
\item[$C^\dagger$] Therefore, 85\% of all University of Colorado Boulder students have some amount of student loan debt. 
\end{description}

This modification does not solve the issue; still, $C^\dagger$ can be false, while $P^\dagger$ true. Even with a large random sample, it is possible that we are unlucky in the sense that the sample percentage differs greatly from the population percentage. A second issue with our argument is that, in inferring from a sample of University of Colorado Boulder students to the population of all University of Colorado Boulder students, we are making some assumptions about the uniformity of nature across time and space. For example, in choosing a random sample, we are assuming that:

\begin{itemize}
	\item the parameter {\it percent of University of Colorado Boulder students who have some amount of student debt} stays constant, at least across short periods of time; and 
	\item students that we have not observed are similar in the relevant ways (e.g., with respect to finances and student debt) to students that we have observed.
\end{itemize}
Taken together, philosophers call generalized versions of these assumptions,%\footnote{That is, (1) parameters stay constant across short periods of time, and (2) units that we have not observed are similar in the relevant ways to units that we have observed.} 
the ``Uniformity Principle'' (UP). The UP states that there is a kind of stability to the world; the parameters that we are attempting to estimate and the laws of nature and regularities that are associated with those parameters stay stable, or themselves change in predictable, lawlike ways. The UP plays a critical role in Hume's claim that there is no strong justification for inductive inference. First, Hume claims that the UP appears to be assumed in any inductive inference. This claim seems quite plausible: any time that we infer a conclusion based on one of the argument types from section \ref{subsubsec:types}---e.g., that all observed electrons have mass of $9.1 \times 10^{-31}$g, therefore all electrons (observed and unobserved) will have this mass---we are implicitly assuming the UP.  So, inductive inference cannot be truly justified without some justification for the UP. And in fact, the UP seems like the crucial premise in need of justifying. 

Once Hume has established the centrality of the UP, he then notes that any justification of the UP must either be deductive or inductive. That is, the UP will either follow necessarily from the premises (deductive); or it will be possible for the premises to be true but for the UP to be false (inductive). As Hume argues, %\footnote{Mention SEP article introduces subtleties and complications} 
the UP cannot be justified deductively, because it's negation does not imply a contradiction; there is nothing incoherent about a universe that isn't uniform across space or time. So, the deductive route will not work. But further, the UP cannot be justified inductively, because any inductive argument justifying the UP would {\it assume} the UP itself, and therefore be circular. Thus, according to Hume, our hopes of justifying inductive inference are hopeless: we have failed to justify the UP, which was a necessary condition for justifying inductive inference.

\section{The problem of induction and statistical philosophies}

Hume's problem of induction is well-known among philosophers, and especially philosophers of science. To be sure, it is a philosophical problem {\it about} science and statistics; contemporary practicing scientists and statisticians do not often engage directly with this problem. Some might even claim that worries about the justifications for the UP and inductive inference are just philosophical quibbling: the lack of a bedrock justification for induction and the UP, they argue, are not real problems for science, at least in not in practice. But there are good reasons to engage with these issues. First, many scientific and statistical methods were developed as a response to known problems with inductive inference, including Hume's problem of induction. The developers of these methods often had the explicit goal of making inductive inferences stronger. The frequentist statistician Ronald Fisher (1890 -- 1962) contextualized his work as a kind of inductive logic in various places, including in papers titled ``Statistical Methods and Scientific Induction'' \citep{fisher1955} and ``The Logic of Inductive Inference''\citep{fisher1935logic}. %As we will discuss in \cref{subsec:Popper} and \cref{chapter:frequentist}, Fisher's work is sometimes thought to be a statistical application of the philosopher Karl Popper's (1902 -- 1994) solution to the problem of induction.  
The first Bayesian analyses---including the work of Reverend Thomas Bayes (1702 -- 1761) and Pierre-Simon Laplace's (1749 -- 1827)---were also developed to solve Hume's problem of induction \citep{stigler2018, Clayton2021}. Engaging with the problem of induction, along with proposed solutions, may help us gain a deeper understanding of the origins, justifications, and utility of standard statistical methods. In turn, we may then be in a better position to critique and apply them correctly. 


%Second, it may be helpful to explicitly acknowledge assumptions like the UP in our statistical practice, and also acknowledge places where the UP is undermined. In the social sciences, lawlike claims do not always stay stable across time; for example ......, Further, even in physics, some question whether fundamental laws are stable across time and space, e.g., see \citet{Murphy2012}.

%MOVE DOWN??: While many, including Fisher and Bayes, have made attempts to solve the problem, many others think that the problem is impossible to solve. For an overview of some famous proposed solutions from philosophers, see \citet{henderson2018}.



%work toward understanding how statistical methods may (or may not!) solve the problem of induction. In order to better understand these methods, we'll first describe the general notion of a statistical model. 


%
%At this point, we might start filling in our argument:
%
%\begin{enumerate}
%\item[{\bf Argument Justifying Inductive Inference}]
%\begin{enumerate}
%\item[$P1$] Inductive inference assumes the UP.
%\item[$P2$] Therefore, any justification of inductive inference must include a justification of the UP.
%\item[$P3$] The UP can be justified inductively or deductively.
%\item[$P4$] A deductive justification of the UP would require the UP to follow necessarily from a set of premises.
%\item[$P5$] There is no deductive justification for the UP. That is, there is no
%\item[$P6$] The UP can be justified inductively or deductively.
%\item[] ...
%\item[$Pn$] ...
%\item[$C$] {\it inductive inferences are justified}
%\end{enumerate}
%\end{enumerate}


%Perhaps we would be justified in adding a premise to {\bf Argument \#4} to better support the conclusion. UNIFORMITY PRINCIPLE...
%\begin{enumerate}
%\item[{\bf Argument \#4$^\ddagger$}]
%\begin{enumerate}
%\item[$P^\dagger$] In a {\it random} sample of $n = 100$ University of Colorado Boulder students, 85 students claimed to have some amount of student loan debt.
%\item[$P^{\dagger\dagger}$] University of Colorado Boulder students that were not observed in the sample are similar in the relevant ways (e.g., with respect to finances and student debt) to students that were in the sample.
%\item[$C^\dagger$] Therefore, 85\% of all University of Colorado Boulder students have some amount of student loan debt. 
%\end{enumerate}
%\end{enumerate}
%
%As noted above, to justify inductive inference, we need to provide an argument for the conclusion $C$: {\it inductive inferences are justified}. The argument that we provide can either be (a) deductive or (b) inductive. 
%
%I might start here by presenting a deductive argument to justify induction, but it will clearly have a premise in need of its own justification: that the future is always like the past. It's not clear how we would justify that premise, other than inductively...


%\section{Statistics as inductive inference}
%%https://plato.stanford.edu/entries/logic-inductive/
%In the last section, we saw that, even though we rely on inductive inferences in everyday reasoning and in statistical reasoning, strictly speaking, inductive inferences are not justified. In this section, we will study some important features of statistical induction, and explore where statistical inferences might go wrong.
%
%... 
%
%data $\to$ statistical procedure $\to$ data transcending conclusion.
%
%Mention where such an inference can go wrong: 
%
%\be
%	\item Data collection might be problematic?biased, bad measuring devices.
%
%	\item statistical procedure could have problems: the statistical model could be wrong. 
%	\item The statistical methodology (e.g., Bayesianism) might make problematic inferences. Even if, in theory it makes good inferences, it might be misused.
%\ee
%
%Inferential statistical methods use tools from mathematics, such as probability, to make inferences from samples to populations. Because, almost always, the sample at hand is a proper subsets of target population, the arguments used in inferential statistics are inductive. Such arguments, as we learned in Section \ref{subsubsec:logic}, contain a conclusion that is supported by, but does not follow necessarily from, the premises. Understood as a type of inductive reasoning, inferential statistics can be classified as a branch of logic; when using inferential statistics, we are providing arguments for conclusions about general populations. As described above, logic is a branch of philosophy. So, perhaps controversially, we might think of statistics as a branch of philosophy as well!
%
%An important feature that separates statistical arguments from other inductive arguments is the use of (deductive) mathematical reasoning to quantify the degree of uncertainty in the conclusion. Consider again, {\bf Argument \#3} from Section \ref{subsubsec:logic}.
%
%\begin{enumerate}
%\item[{\bf Argument \#3}]
%\begin{enumerate}
%\item[P1] The car salesman claimed that George's 1989 Chrysler LeBaron convertible was owned by the actor Jon Voight.
%\item[P2] The owner's manual shows that the previous owner's last name was Voight.
%\item[C] Therefore, the previous owner of George's car was Jon Voight.
%\end{enumerate}
%\end{enumerate}
%
%This argument does nothing to quantify the degree to which the premises support the conclusion. Now, consider the following argument:
%
%\begin{enumerate}
%\item[{\bf Argument \#5}]
%\begin{enumerate}
%\item[P1] Fifty five percent of people in a random sample of 200 patrons of Poppy's Italian Restaurant said that they prefer fusilli pasta over rigatoni. 
%\item[] [...Other premises involving a statistical model, a method of inference based on that procedure...]
%\item[C] Thus, with 95\% confidence, between 47 percent and 63 percent of all patrons of Poppy's prefers fusilli pasta over rigatoni.
%\end{enumerate}
%\end{enumerate}
%
%Unlike {\bf Argument \#3}, {\bf Argument \#5} does attempt to quantify the degree to which the premises support the conclusion. In particular, we are 95\% confident that the conclusion follows from the premise in {\bf Argument \#5}.What the word ``confidence'' actually means depends on the statistical methods used in calculations. We will explore different paradigms, that, in turn, lead to different statistical calculations, in Chapters 4 and 5.
%
%In order to make the sort of inference made in {\bf Argument \#5}, statisticians must think carefully about 


%%%%%%%%%%%%%%%
%\section{Statistical models}
%\label{subsec:models}
%Common to all paradigms in statistics is the use of probability theory, perhaps in conjunction with some ``substantive'' empirical theory, to model the observed data \citep{Spanos2019}. Suppose that we observe data $\mathbf{x} = (x_1,...,x_n)$, and assume that the data are {\it realizations} of a stochastic (probabilistic) process $\mathbf{X} = (X_1,...,X_n)$. This assumption is often justified in terms of repeated sampling. We might assume that, {\it if} we observed the same phenomena (e.g., experiment, physical process) again under sufficiently similar conditions, we would have observed different values $\mathbf{x} = (x_1,...,x_n)$. \citet{Howson2005} write that
%
%\begin{quote}
%The assumption of...[stochasticity] is more or less realistic in many cases, for instance, where an instrument is used to measure some physical quantity. The instrument would, as a rule, deliver a spread of results if used repeatedly under similar conditions, and experience shows that this variability, or error distribution, often approximates a normal curve.
%\end{quote}
%Stochasticity enters here as an assumption about what {\it would have happened}; the world would have been different if we repeated the sampling process again. %(SOMETHING ON INHERENT STOCHASTICITY, LAPLACE'S DEMON?)
%
%
%
%In the simplest case, we might be lucky enough that the data are {independent and identically distributed (iid)}. Informally:
%
%\be
%	\item[(i)] $X_i$ is independent from $X_j$ if the occurrence of $X_i$ does not influence the probability of occurrence of $X_j$, for all $i,j = 1,...,n$, $i \ne j$. 
%	\item[(id)]  $X_1,...,X_n$ are assumed to have the same probability distribution, i.e., the same ``shape'' (e.g., normal), center, scale, etc.
%\ee
%For example, if $\mathbf{X} = (X_1,X_2)$ represents the stochastic process of drawing two playing cards from a shuffled standard deck\footnote{An explanation of a standard deck of playing cards can be found here: https://bit.ly/2ZupVHK} {\it without replacement}, then the probability of drawing, say, $2\diamondsuit$ after having drawn $K\heartsuit$ is different from just the probability of having drawn $2\diamondsuit$. Thus, such a stochastic process is not iid because violates the independence assumption. As another example, if $Y_1 \sim N(0,1)$ and $Y_2 \sim N(0.5,1)$, then $\mathbf{Y} = (Y_1,Y_2)$ is not iid, because it violates the identically distributed assumption.  
%
%Under the assumption that $\mathbf{X} = (X_1,...,X_n)$ is an iid stochastic process, we can typically\footnote{But not always! Some random variables do not have density functions. For example, see https://bit.ly/2ZDYpqz} write down the joint probability density (or mass) function (pdf) associated with the stochastic process. As a general shorthand, we might write that $\mathbf{X} \overset{iid}{\sim}  f(\mathbf{x}; \boldsymbol\theta),$ where $\boldsymbol\theta$ is a vector of parameters coming from some set $\boldsymbol\Theta \subset \mathbb{R}^m$, and $\mathbf{x} \in \mathbb{R}^n_\mathbf{x}$. Using these ingredients, we can define the {\it statistical model} associated with data $\mathbf{x} = (x_1,...,x_n)$ as
%
%\begin{align}\label{eq:model}
%\mathcal{M}_{\boldsymbol\theta}(\mathbf{x}) = \{\, \big(\, \mathbf{X}, \, f(\mathbf{x}; \boldsymbol\theta) \, \big) :  \boldsymbol\theta \in \boldsymbol\Theta, \, \, \mathbf{x} \in \mathbb{R}_\mathbf{x}^n\}.
%\end{align}
%That is, the statistical model, $\mathcal{M}_{\boldsymbol\theta}(\mathbf{x})$, is a pair $\big( \, \mathbf{X}, \, f(\mathbf{x}; \boldsymbol\theta) \, \big)$, where $\mathbf{X}$ is the sample of possible observations, and $f(\mathbf{x}; \boldsymbol\theta)$ is the set of possible probability distributions on observations, parameterized by $\boldsymbol\theta \in \boldsymbol\Theta$.
%
%%\be
%%	\item A sample space, $\Omega$. $\Omega$ is a collection of all possible outcomes of the probabilistic process.
%%	\item A set of all (measurable) events, $\mathcal{F}$. Events are sets of outcomes.
%%	\item A sample, i.e., random variables $\mathbf{X} = (X_1,...,X_n)$ that map events to (typically) numbers $\mathbf{X}: \mathcal{F}^n \to \mathbb{R}^n$.
%%\ee
%% with the sample $\mathbf{X} = (X_1,...,X_n) \overset{iid}{\sim}  f(\mathbf{x}; \boldsymbol\theta)$ 
%%
%
%For example, suppose that we have good reason to believe that the observed data,  $\mathbf{x} = (x_1,...,x_n)$, can be modeled by  $\mathbf{X} = (X_1,...,X_n)$, where each $X_i$ comes from a  univariate normal distribution. Thus, each $X_i$ has the following pdf:
%
%\begin{align*}
%f(x; \mu, \sigma) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp{\bigg\{-\frac{(x-\mu)^2}{2\sigma^2} \bigg\} },
%\end{align*}
%with parameters $\boldsymbol\theta = (\mu, \sigma)$, where $\mu$ is the mean and $\sigma$ is the standard deviation. Under the assumption that the sample is iid, the joint pdf associated with the sample is $$ f(\mathbf{x}; \mu, \sigma) = \prod_{i=1}^n f(x_i; \mu, \sigma), $$ because the joint distribution of independent random variables is the product of the marginal distributions. So, our statistical model can then be written as
%\begin{align*}
%\mathcal{M}_{\boldsymbol\theta}(\mathbf{x}) = \{\, \big(\, \mathbf{X}, \, f(\mathbf{x}; \boldsymbol\theta) \, \big) :  \boldsymbol\theta = (\mu, \sigma) \in \boldsymbol\Theta = \mathbb{R}^2, \, \, \mathbf{x} \in \mathbb{R}^n\}.
%\end{align*}
%The goal of the statistical model is to accurately describe the data generating process, and to allow for inferences about important parameters of interest. Such parameters of interest might be $\boldsymbol\theta$ itself, or some function of $\boldsymbol\theta$, say, $\boldsymbol\tau = g(\boldsymbol\theta)$.
%
%How does this formalization of a statistical model help tackle the problem of induction? Recall that the problem arises because we have no way of formally justifying the methodological procedure of inductive inference. A deductive argument cannot justify induction because of the very nature of inductive inference; deductive arguments produce a conclusion that follows necessarily from the premises, but inductive arguments contain no necessary relation. On the other hand, an inductive attempt to justify induction would, itself, require a justification, which would lead to an infinite regress.  Statistical models may provide a mathematical formalization that makes induction more rigorous by quantifying our uncertainty in the conclusions we draw from them.

%%%%%%%%%%%%%%%%%%%%%%

%\begin{quote}{}
%A loose analogy exists between Popperian philosophers and frequentist statisticians, on the one hand, and Carnapian philosophers and Bayesian statisticians on the other. The latter hold that probability needs to supply some degree of belief, support, or epistemic assignment to hypotheses ... a position that Popperians, or critical rationalists, dub ‘justificationism’...Denying that such degrees may be usefully supplied, Popperians, much like frequentists, advocate focusing on the rationality of rules for inferring, accepting, or believing hypotheses. But what properties must these rules have?'' \citep{mayo_spanos_2011}.
%\end{quote}
%Broadly construed, there are two types of solutions to the problem of induction: those that use probability theory to assign degrees of belief, credence, or confirmation to scientific theories and hypotheses, and those that do not. These two types of solutions provide the philosophical starting points---both historically and logically---for the Bayesian and frequentist statistical inference paradigms. 

\subsection{The falsification solution}
\label{subsec:Popper}
\begin{quote}
Every experiment may be said to exist only in order to give the facts a chance of disproving the null hypothesis.
\end{quote}
\begin{flushright}
— R.A. Fisher, {\it Design of Experiments}
\end{flushright}

\noindent Philosopher of science Karl Popper recognized that Hume's problem of induction was, in a certain sense, insurmountable. Popper writes:
\begin{quote}
Hume, I felt, was perfectly right in pointing out that induction cannot be logically justified. He held that there can be no valid logical arguments allowing us to establish `that those instances, of which we have had no experience, resemble those, of which we have had experience'. Consequently `even after the observation of the frequent or constant conjunction of objects, we have no reason to draw any inference concerning any object beyond those of which we have had experience' \citep{Popper2010}.
\end{quote}
As a result, Popper made no attempt to solve the problem of induction by {\it justifying} induction. Rather, he denied that induction was necessary for the proper functioning of science. Instead of generalizing from observations to theories (e.g., scientific laws), Popper believed that science properly functions by first posing the theories, and then testing those theories against particular relevant data. In this way, the proper justificatory structure of science is {\it deductive} rather than {\it inductive}: a scientific theory $T$, so Popper claimed, can be conclusively falsified given certain empirical evidence. As an example, consider the theory $T$: {\it All ravens are black}. This theory can be conclusively and deductively falsified with the observation of (at least) one non-black raven. The argument would be:

\begin{description}
	\item[{\bf P1}:] If $T$: {\it all ravens are black}, then any raven observed will be black.
	\item[{\bf P2}:] A white raven was observed.
	\item[{\bf C}:] Therefore, $T$ is false. 
\end{description}
This general argument form,
\begin{description}
	\item[{\bf P1}:] If $T$, then $e$.
	\item[{\bf P2}:] Not $e$.
	\item[{\bf C}:] Therefore, not $T$.
\end{description}
is valid, and therefore, deductive. For Popper, {\it falsification}---the process of proposing theories and attempting to refute them---rather than induction, is the real mode of scientific progress.

To be sure, this view has some problems. For one, we might notice that there is an asymmetry between our ability to (1) reject $T$ as false, i.e., when evidence $e$ contradicts $T$; and (2) accept $T$ as true, i.e., when $e$ does not contradict $T$. In case (1), practically speaking, most scientific theories and hypotheses are not as easily and clearly falsifiable as $T$. Consider the health science hypothesis $H$: {\it A high carbohydrate diet causes an increase in body weight}. What evidence would {\it conclusively} falsify $H$? Perhaps, in theory, such evidence exists. We can {\it imagine} a world in which any time someone increases their carbohydrate intake for several weeks, they also increase their body weight. In such a world, we might argue:
\begin{description}
	\item[{\bf P1}:] If $H$: {\it a high carbohydrate diet causes an increase in body weight}, then any individual observed eating a high carbohydrate diet will see an increase in body weight.
	\item[{\bf P2}:] Thom eats a high carbohydrate diet but has {\it not} seen an increase in body weight.
	\item[{\bf C}:] Therefore, $H$ is false. 
\end{description}
However, our imagined world is not the real world; in the real world, diet is complicated. There are many other factors that also influence body weight. Strict falsification is much more difficult to attain. Statistical methods attempt to control for these other factors---as well as random variation---to isolate the effect of diet on body weight. But even then, do we know we controlled for all of the right factors? How do we know that we did not leave something out, or that random variation, rather than diet, led us to reject $H$? Conclusive falsification seems, in practice at least, unattainable. It is not clear exactly what evidence we could practically attain that would allow us to conclusively falsify most real-world scientific hypotheses. As we will see in \cref{chapter:frequentist},  \cref{chapter:Bayesian}, and \cref{chapter:causation}, statistical philosophies, including causal inference, can help us make inferences and practical decisions in the absence of conclusive falsification.

In case (2), $e$ being broadly consistent with $T$ does not confirm $T$, because $e$ will be consistent with other (in fact, infinitely many other) theories, $T_i$, each of which is not equivalent to $T$. Yet another observed black raven does not confirm $T$, and there are many other theories consistent with new observation (e.g., $T_1$: {\it ravens are $60\%$ black and $40\%$ white}).  Popper's solution to this problem is to introduce the notion of corroboration.  A theory $T$ is {\it corroborated} by $e$ if $e$ were produced  by a ``severe test''. By a ``severe test'', Popper means ``tests that would probably have falsified a claim if false'' \citep{Mayo2018}. Note that corroboration is not strict confirmation, if by `confirmation' one means {\it conclusively true}. Instead, corroboration is a building up of support for $T$, through the right kinds of probes. %However, the notion of a severe test was not formalized until decades later by philosophy of statistics Deborah Mayo.

If one is familiar with the statistical hypothesis testing developed by Ronald Fisher, Jerzy Neyman (1894 -- 1981), and Egon Pearson (1895 -- 1980), Popper's logic of conjecture and refutation should not be entirely foreign.\footnote{Hypothesis testing was developed separately by Fisher, on the one hand, and Neyman and Pearson on the other. The version often taught is a blend of these two methods.} In statistical hypothesis testing, and in Popper's falsification paradigm, a hypothesis is put forward, and a statistical procedure is conducted to attempt to falsify it. Interestingly, classical frequentist hypothesis testing starts and ends with conjecture and refutation; there was no formal method for corroboration or so-called severe testing. More recently, philosophers Deborah Mayo and Aris Spanos developed a set of statistical tools that formalize the notion of a severe test, which, when used correctly, can help corroborate hypotheses \citep{mayo_spanos_2011b, Mayo2018}. In \cref{chapter:frequentist}, we will study the statistical procedures that Fisher, Neyman, Pearson, Mayo, and Spanos have developed to deal with messy, real-world scientific theories and hypotheses.

So, do falsification and hypothesis testing succeed in solving the problem of induction? We will not be able to adequately address this question until \cref{chapter:frequentist}. But, as we will see, under the statistical assumptions posed in a statistical model, hypothesis testing provides a framework for quantifying uncertainty in our conclusions and behaviors by controlling error rates over the long run. This error control represents an important step forward in strengthening inductive inference: if the modeling assumptions are (roughly) met, we know how often we will be in error in the long run. While this paradigm does make explicit and precise statements about probabilities, it still assumes the UP---i.e., by making claims about ``the long run''. But, as we saw in section \ref{subsec:PoI}, the UP cannot be justified without circularity. So, in failing to avoid the UP, strictly speaking, these statistical method has failed to circumvent the problem of induction. Nevertheless, these methods provide some guidance for belief and action under uncertainty. 



%%%%%%%%%%%%%%%%%***** MOVE BELOW TO CH 4??? ******

%To get a sense how statistical hypothesis testing works, recall the statistical model associated with data $\mathbf{x} = (x_1,...,x_n)$, given in equation \eqref{eq:model}.
%%\begin{align*}
%%\mathcal{M}_{\boldsymbol\theta}(\mathbf{x}) = \{\, \big(\, \mathbf{X}, \, f(\mathbf{x}; \boldsymbol\theta) \, \big) :  \boldsymbol\theta \in \boldsymbol\Theta, \, \, \mathbf{x} \in \mathbb{R}^n\}.
%%\end{align*}
%Broadly,\footnote{Fisher and Neyman-Pearson had different versions of hypothesis tests. For our purposes here, we can safely ignore those differences.}
%%and we will consider some of the differences between the two, and whether those differences render the two versions incompatible, in Chapter \ref{chapter:frequentist}.} 
%a statistical hypothesis test works as follows:
%
%\be
%	\item Specify two hypotheses, 
%		\begin{align*}
%			H_0&: \theta \in \Theta_0 \\
%			H_1&: \theta \in \Theta \setminus \Theta_0
%		\end{align*} 
%where $\Theta_0 \subset \Theta$. $H_0$ is referred to as the {\it null hypothesis} because it often refers to parameter values that reflect ``no effect'' or ``no relationship'' among variables. $H_1$ is referred to as the {\it alternative hypothesis}. In the simplest case, where $\Theta_0 = \{\theta_0 \}$, the statistical model is reduced to a single distribution over $\mathbf{X}$, because the null hypothesis contains only a single point.  
%	\item Decide on a distance measure, $d(\mathbf{X})$, for the sample, under $H_0$. This measure is called the {\it test statistic}. It is a distance measure in the sense that it will differ from sample to sample, and the differences in $d(\mathbf{X})$ will track how ``rare'' the sample is.
%	\item Specify a {\it rejection region}---a region of the output of $d(\mathbf{X})$ that corresponds to a ``rare'' dataset, under $H_0$.  
%	\item Collect the relevant data $\mathbf{x}$ and calculate $d(\mathbf{x})$ under $H_0$. If $d(\mathbf{x})$ falls within the pre-specified rejection region, then we may infer that the data indicate a genuine deviation from $H_0$. If $d(\mathbf{x})$ falls outside of the rejection region, then we do not have an indication of a genuine deviation from $H_0$ \citep{Mayo2018}. 
%\ee
%Before we consider a simple example, notice the similarities between this formal set up, and Popper's less formal way of conjecture and refutation. Hypotheses are specified. With the right evidence, some hypotheses are considered suspect, but many hypotheses still remain viable. Note also that the failure to falsify a null hypothesis $H_0$ does not constitute evidence for it. Similarly, with Popper, the failure to falsify does not imply corroboration. We need something else (i.e., a severe test).
%
%\subsubsection{A hypothesis testing example}

\subsection{The Bayesian solution}

The most popular alternative to Popper's falsificationist framework---and falsificationist statistical methods like hypothesis testing---is called {\it probabilism}. Probabilism is the view that conclusions, theories, and hypotheses can be assigned a degree of support through the use of probability theory \citep{Mayo2018}. Probabilism assigns theories a number between zero and one, which represents, roughly, how plausible the theory is. Perhaps we have the following argument:
\be
	\item[{\bf P1}:] Over one million ravens have been observed, and all have been black.
	\item[{\bf T}:] Therefore, {\it all ravens are black}.
\ee
Intuitively, $T$ has strong support. Probabilism might assign $T$ a number close to one. It is {\it possible} that $\neg T$: {\it some ravens are not black}. But given the lack of evidence, $\neg T$ would be assigned a low number, close to zero.

Various attempts have been made to formalize probabilism as a theory of inductive logic \citep{Bayese_Price_1763, cox1946probability, carnap1962logical}. The most famous form of probabilism, with the closest connection to statistical practice, is Bayesian probabilism. Bayesian probabilism makes use of Bayes' theorem to update probabilities assigned to theories based on observed evidence. For example, suppose that we start out by assigning $H$: {\it a high carbohydrate diet causes an increase in body weight} a probability of $0.3$. Nutrition researchers studying this hypothesis conduct a study and find that $e$: {\it on average, participants on a high carbohydrate diet gained 3 pounds more than those on a low carbohydrate diet}. Suppose that the probability of observing $e$ if $H$ were true is $P(e \, | \, H) = 0.8$, and the probability of $E$ if $H$ were false is $P(e  \,| \, \neg H) = 0.4$. Bayes' theorem states that\footnote{If this formulation of Bayes' theorem does not look familiar to you, do not worry. We will discuss Bayes' theorem in detail in \cref{chapter:Bayesian}.}
\begin{equation}
\begin{aligned}
P(H \,|\, e) &= \frac{P(e \, | \, H)P(H)}{P(e \,|\, H)P(H) + P(e \,| \,\neg H)P(\neg H)}  \\
&= \frac{(0.8)(0.3)}{(0.8)(0.3) + (0.4)(0.7)} \approx 0.46.
\end{aligned}
\end{equation}

Thus, the updated probability of $H$, based on observing $e$, is higher. Probabilism aids inductive logic, in the sense that it provides a number that quantifies the strength of the conclusion (i.e., the theory or hypothesis) given the premises (evidence and assumptions). 

Probabilism also has its problems. Many prominent philosophers and statisticians---Popper and Fisher among them---are vehemently opposed to the use of probability to confirm hypotheses. Popper argued that the degree of confirmation that $e$ confers on $H$ is not the same as the probability of $H$ given $e$ \citep{popper2005logic, Mayo2018}. \citet{Chapman2015} argues that, contrary to the starting point of probabilisim, {\it probability} is not equipped to extend deductive logic to reasoning about {\it plausibility} (i.e., uncertain reasoning). Fisher wrote that ``probability is a ratio of frequencies, and about the frequencies of such [hypotheses] we can know nothing whatever'' \citet{Fisher1922}.\footnote{We will consider issues related to interpretations of probability---e.g., whether probability {\it just is} a ratio of frequencies or not---in \cref{chapter:probability}.} A primary problem for these thinkers is that probabilism relies on an epistemic interpretation of probability. Such an interpretation allows for probabilities to be assigned to fixed, non-repeatable features of the world. It's not clear how such probability assignments arise. How did we come up with $P(H) = 0.3$? It is not tied to any repeatable process. It seems like we just made it up! For those that reject Bayesian probabilism, all probabilities must arise from empirical phenomena, and ought to be reserved for events that are (at least theoretically) repeatable. 

As with falsification and frequentist hypothesis testing, we might ask: does Bayesian probabilism provide a solution to the problem of induction? Again, we will not be able to adequately address this question until we study Bayesian inference in more depth, in \cref{chapter:Bayesian}.  Bayesian inference provides a formal framework for assessing how evidence bears on different hypotheses. Specifically, under the statistical assumptions, Bayesian inference assigns a ``plausibility score'', in the form of a probability, to each hypothesis, e.g., $P(H \,|\, e)  \approx 0.46.$. These probability assignments represent an important step forward in strengthening inductive inference: if the modeling assumptions are (roughly) met then the probabilities of various hypotheses are interpreted as our degrees of belief in those hypotheses. The higher the probability, the more likely the hypothesis is to be true. While it does make explicit and precise statements about degrees of belief in various hypotheses, it still assumes that the future will be roughly like the past, i.e., it assumes the UP. But, as we saw in section \ref{subsec:PoI}, the UP cannot be justified without circularity. So, in failing to avoid the UP, this statistical method has failed to circumvent the problem of induction. Nevertheless, Bayesian methods provide some guidance for belief and action under uncertainty. \\ \\ \\ 


Although, strictly speaking, the statistical inference methods described in this chapter do not {\it solve} the problem of induction, they go a long way toward placing induction on a stronger foundation. These methods are also quite different from each other. One champions falsification and refutation, and the other assigns probabilities directly to theories and hypotheses. What allows for these differences? Which one provides a stronger foundation for inductive inference? Are there other statistical inference paradigms that do better? The goal of the next few chapters will be to answer these questions. 





%%%%%%%%%BAYES EXAMPLE%%%%%%%%%%%%
%MOVE TO CH 5?%
%Bayesian inference still makes use of statistical models, with a definition slightly modified from the one given in equation \eqref{eq:model}. The Bayesian model can be written as:
%
%\begin{align}\label{eq:bayesmodel}
%\mathcal{M}_{\boldsymbol\theta}(\mathbf{x}) = \{\, \big(\, \mathbf{X}, \, f(\mathbf{x}, \boldsymbol\theta) \, \big) :  \boldsymbol\theta \in \boldsymbol\Theta, \, \, \mathbf{x} \in \mathbb{R}^n\}.
%\end{align}
%Note that the only difference between equation \eqref{eq:model} and equation \eqref{eq:bayesmodel} is that $f(\mathbf{x}; \boldsymbol\theta)$---the joint probability distribution of the data, assuming a fixed value of the parameter---is replaced by $f(\mathbf{x}, \boldsymbol\theta)$---the joint probability distribution over the data {\it and} the parameters. Bayesians allow for probability assignments over parameters, which allows them to use and interpret statistical models quite differently than Fisher's and Neyman-Pearson's frequentist inference.
%
%%Recall again that a statistical model associated with data $\mathbf{x} = (x_1,...,x_n)$ is given as......
%
%In theory, from $f(\mathbf{x}, \boldsymbol\theta)$, one can compute:
%
%\begin{align*}
%f(\mathbf{x}) &= \int f(\mathbf{x}, \boldsymbol\theta)d\boldsymbol\theta \,\,\,\,\,\,\, \text{(The marginal distribution of the data)}, \\
%\pi(\boldsymbol\theta) &= \int f(\mathbf{x}, \boldsymbol\theta)d\mathbf{x} \,\,\,\,\,\,\, \text{(The marginal/prior distribution of the parameters)},\\ 
%f(\mathbf{x} \, | \, \boldsymbol\theta) &= \frac{f(\mathbf{x}, \boldsymbol\theta)}{f(\mathbf{x})} \,\,\,\,\,\,\, \text{(The likelihood of the data given the parameters)},
%\end{align*}
%and ultimately, by {\it Bayes' theorem}:
%\begin{align}\label{eq:bayes}
%\pi(\boldsymbol\theta  \, | \, \mathbf{x}) &= \frac{f(\mathbf{x} \, | \, \boldsymbol\theta)\pi(\boldsymbol\theta)}{f(\mathbf{x})} =  \frac{f(\mathbf{x} \, | \, \boldsymbol\theta)\pi(\boldsymbol\theta)}{\displaystyle \int f\left(\mathbf{x} \, | \, \boldsymbol\theta\right)\pi(\boldsymbol\theta)d\boldsymbol\theta}.
%\end{align}
%The goal of Bayesian inference is to obtain the left hand side of Bayes' theorem; this function, $\pi(\boldsymbol\theta  \, | \, \mathbf{x})$, is called the {\it posterior distribution} of $\boldsymbol\theta$ given $\mathbf{x}$, and is a probability distribution over hypotheses about the parameter, $\boldsymbol\theta$, given data $\mathbf{x}$. In practice, statisticians typically do not have $f(\mathbf{x}, \boldsymbol\theta)$, but instead construct the likelihood function, $f(\mathbf{x} \, | \, \boldsymbol\theta)$, using modeling assumptions about the data generating process.\footnote{Here, $f\left(\mathbf{x} \, | \, \theta\right)$ is mathematically equivalent (but not philosophically or statistically equivalent!) to $f\left(\mathbf{x} \, ; \, \theta\right)$ as given in equation \eqref{eq:model}; that is, $f\left(\mathbf{x} \, | \, \theta\right)$ is the joint pdf of the data interpreted as a function of $\theta$. Bayesians use ``|'' rather than ``;'' for reasons that will become clear in our chapter on the interpretation of probability theory. } The prior distribution, $\pi(\boldsymbol\theta)$---perhaps the most controversial component of Bayesian inference---is set by the researcher(s) before obtaining data. 
%%When a joint pdf is interpreted as a function of the parameter $\theta$, with the data fixed, rather than as a function of the data, with $\theta$ fixed, it is called the likelihood function.
%We'll say more about the statistical and philosophical details of Bayesian inference in Chapter \ref{chapter:Bayesian}. For now, we'll note that Bayesian inference allows us to quantify our degree of belief in different hypotheses, i.e., different values of $\boldsymbol\theta$, after observing data. For example, the result of a Bayesian inference might be that, given the modeling assumptions (to be made more explicit below), we are justified in believing $H_0: \theta \le 0$  is five times more likely than $H_0: \theta > 0$. \\
%
%
%To see how Bayesian inference works in practice, consider again the research question about refrigerator energy consumption from the previous section. Let $\mu_1$ be the mean energy consumption in the unmodified refrigerator group, and $\mu_2$ be the mean energy consumption in the modified refrigerator group. For the sake of mathematical simplicity, let's assume that we have enough experience with the unmodified group to know that $\mu_1 = 1.5$. Using this assumption, Marilynne's statistical hypotheses can be written as:
%	\begin{align*}
%		S_0: 	\mu_1=\mu_2 \iff \mu_2 = 1.5 \\
%		S_1: 	\mu_1\ne \mu_2 \iff  \mu_2 \ne 1.5.
%	\end{align*}
%In Bayesian inference, we must start by specifying a prior distribution on the parameter of interest, $\theta = \mu_2$. The prior distribution will specify a probability distribution over the relevant values of $\mu_2$, {\it before observing the data}. It quantifies our degree of belief in $\mu_2$ before collecting observations. In this case, a reasonable choice might be a normal distribution of $\mu_2$, centered at $\mu_0 = 1.5$, with variance $\sigma_0^2 = 1$:
%
%$$\mu_2 \sim N\left(\mu_0 = 1.5, \sigma_0^2 = 1\right).$$
%Informally, by selecting this prior distribution, we are stating that we believe it is very likely that the true value of $\mu_2$ is relatively close to $1.5$ (i.e., the normal distribution has its peak at $1.5$, the value under $H_0$), and less likely that $\mu_2$ is far from $1.5$ in either direction. This prior quantifies our belief that, before observing the data, there is a high probability that the modified group is no different than the unmodified group. The goal of a Bayesian analysis is to update our prior based on the data. This update results in a {\it posterior distribution}, $\pi\left(\mu_2 \, | \, \mathbf{x} \right)$, our degree of belief in $\mu_2$ given the data $\mathbf{x}$. 
%
%%\begin{align*}
%%\end{align*}
%%Let's analyze Bayes' theorem, equation \eqref{eq:bayes}, in the context of this problem.
%%
%%\begin{enumerate}
%%	\item First, note that the lefthand side is a probability distribution over $\theta$ given the data $\mathbf{x}$, i.e., the posterior distribution $\pi\left(\theta \, | \, \mathbf{x} \right)$ is a function of $\theta$. It quantifies our degree of belief in $\theta$ given the data.
%%	\item Second, note that, on the righthand side, the denominator is an integral over $\theta$.  So, $\theta$ will be ``integrated out''---that is, the denominator will not contain $\theta$, but only $\mathbf{x}$ (along with other constants). Consequently, the denominator does not contribute to the shape or position of $\pi\left(\theta \, | \, \mathbf{x} \right)$; instead, it is just a normalizing constant, setting the height of $\pi\left(\theta \, | \, \mathbf{x} \right)$.
%%	\item The shape and position of the posterior distribution are set by the numerator on the righthand side. That numerator combines our pre-data prior beliefs about $\theta$, $\pi(\theta)$, with information contained in the data, encoded by the likelihood, $f\left(\mathbf{x} \, | \, \theta\right)$. So, our posterior degree of belief in $\theta$ given $\mathbf{x}$ is an update of our prior beliefs based on the data!
%%	
%%\end{enumerate}
%
%With respect to Marilynne's refrigerators, since measurements were assumed to be normally distributed, 
%
%\begin{align*}
%f\left(\mathbf{x} \, | \, \mu_2\right) = \left(2\pi\sigma^2\right)^{-n/2}\exp{\bigg\{-\frac{1}{2\sigma^2}\sum^n_{i=1}\left(x - \mu_2 \right)^2 \bigg\}}. 
%\end{align*}
%Again, for simplicity, we'll assume that the standard deviation of the modified group measurements is known to be $\sigma = 0.3$. The prior distribution over $\mu_2$ is given by:
%
%\begin{align*}
%\pi\left(\mu_2  \right) = \frac{1}{\sqrt{2\pi}}\exp{\bigg\{-\frac{1}{2} \left(\mu_2 - 1.5 \right)^2 \bigg\}}.
%\end{align*}
%It can be shown that the posterior distribution on $\mu_2$ given the data is normal:
%
%\begin{align*}
%\mu_2 \, | \, \mathbf{x}  \,\, &\sim \,\, N\left( \underbrace{\left( \frac{1}{\sigma_0^2} + \frac{n}{\sigma^2}\right)^{-1}\left(\frac{\mu_0}{\sigma_0^2} + \frac{n\bar{x}}{\sigma^2} \right) }_{\mu_{post}} \,\, , \,\, \underbrace{ \left( \frac{1}{\sigma_0^2} + \frac{n}{\sigma^2}\right)^{-1} }_{\sigma^2_{post}} \right) \\
%&\sim N\left(1.536, 0.003 \right).
%\end{align*}
%The posterior distribution on $\mu_2 \, | \, \mathbf{x} $ provides us with degrees of belief about $\mu_2$ after seeing the data. So, we can answer questions such as: what is the probability that the mean of the modified group is greater than the mean of the unmodified group? The posterior distribution tells us that:
%
%$$P\left(\left[\mu_2 \, | \, \mathbf{x} \right] > 1.5 \right) \approx 0.74.$$

%As with frequentist analyses, we might ask: does this framework provide a solution to the problem of induction? Bayesian inference provides a formal framework for assessing how evidence bears on different hypotheses. Specifically, under the statistical assumptions, Bayesian inference assigns an ``uncertainty score'', in the form of a probability, to each hypothesis, e.g., the hypothesis $\left[ \mu_2 \, | \, \mathbf{x} \right] > 1.5$. These probability assignments represent an important step forward in strengthening inductive inference: if the modeling assumptions are (roughly) met then the probabilities of various hypotheses are interpreted as our degrees of belief in those hypotheses. The higher the probability, the more likely hte hypothesis is to be true.
%
%Ultimately, the statistical method described here fails to be a solution to the problem of induction. While it does make explicit and precise statements about degrees of belief in various hypotheses, it still assumes that the future will be roughly like the past, i.e., it assumes the UP. But, as we saw in section \ref{subsec:PoI}, the UP cannot be justified without circularity. So, in failing to avoid the UP, this statistical method has failed to circumvent the problem of induction. \\ \\ \\ 


%I HAVE CODE FOR THE MARILYNNE EXAMPLE IN TERMS OF BAYES FACTORS %helpful resource: https://richarddmorey.github.io/BayesFactor/#twosample



%MAY BE HELPFUL: https://statswithr.github.io/book/hypothesis-testing-with-normal-populations.html#sec:known-var


